{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPFyUOcSCfGFtJ2r+Mnft0v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k4ilham/jupiter/blob/main/Deep_Neural_Network_Prostate_GSE6919_U95B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "22u3uugOo-Ee"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.activations import relu\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "import warnings;\n",
        "warnings.filterwarnings('ignore');"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "jpJSKkKKSNgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load Data from CSV\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/k4ilham/dataset/main/Prostate_GSE6919_U95B.csv')"
      ],
      "metadata": {
        "id": "7SU0gQvspNix"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Rr5NZS4IpdI8",
        "outputId": "55ebd7b4-ccea-4dcd-c640-615aa12677e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         samples                    type  41880_at  41881_at  41882_at  \\\n",
              "0  GSM152992.CEL  primary_prostate_tumor  2.414076  4.113824  2.035911   \n",
              "1  GSM152993.CEL  primary_prostate_tumor  2.385157  4.078664  2.123064   \n",
              "2  GSM152994.CEL  primary_prostate_tumor  2.295522  4.085505  2.144344   \n",
              "3  GSM152995.CEL  primary_prostate_tumor  2.260478  4.466391  2.206410   \n",
              "4  GSM152996.CEL  primary_prostate_tumor  2.229731  4.291435  2.506255   \n",
              "5  GSM152997.CEL  primary_prostate_tumor  2.323719  4.042794  2.219460   \n",
              "6  GSM152998.CEL  primary_prostate_tumor  2.557032  4.196903  2.122405   \n",
              "7  GSM152999.CEL  primary_prostate_tumor  2.441765  4.148545  1.968985   \n",
              "8  GSM153000.CEL  primary_prostate_tumor  2.604707  4.234341  2.167552   \n",
              "9  GSM153001.CEL  primary_prostate_tumor  2.364670  4.183144  1.866217   \n",
              "\n",
              "   41883_at  41884_at  41885_at  41886_r_at  41887_at  ...  AFFX-ThrX-3_at  \\\n",
              "0  3.102248  2.115578  1.775455    6.107839  2.160168  ...        2.955998   \n",
              "1  3.087631  2.254190  1.815183    5.708878  2.134447  ...        3.196521   \n",
              "2  3.071539  2.229422  1.985899    5.679248  2.100443  ...        2.929904   \n",
              "3  3.505265  2.605014  1.887307    5.935039  2.261295  ...        3.578538   \n",
              "4  3.220628  2.404673  1.886664    5.965917  2.274317  ...        3.558184   \n",
              "5  3.030761  2.539964  1.836586    5.970438  1.880250  ...        3.442099   \n",
              "6  3.495034  2.353686  2.100858    6.338756  2.019285  ...        3.542867   \n",
              "7  3.230116  2.240704  1.896051    6.166129  2.012576  ...        3.363998   \n",
              "8  3.394769  2.294088  2.089270    6.190621  2.030608  ...        3.703331   \n",
              "9  3.169024  2.371755  1.983816    5.748455  2.142535  ...        3.077640   \n",
              "\n",
              "   AFFX-ThrX-5_at  AFFX-ThrX-M_at  AFFX-TrpnX-3_at  AFFX-TrpnX-5_at  \\\n",
              "0        2.910953        2.095267         1.617076         2.060144   \n",
              "1        2.975412        2.249950         1.757867         2.352185   \n",
              "2        2.857025        2.047436         1.625339         2.065674   \n",
              "3        3.420946        2.736342         1.940826         2.713500   \n",
              "4        3.083316        2.562048         1.923414         2.775842   \n",
              "5        3.239850        2.373556         1.973410         2.563835   \n",
              "6        3.178389        2.413796         2.038962         2.723099   \n",
              "7        3.314865        2.345718         1.927122         2.600874   \n",
              "8        3.263648        2.769345         2.183191         2.621211   \n",
              "9        3.048728        2.230446         1.928804         2.466815   \n",
              "\n",
              "   AFFX-TrpnX-M_at  AFFX-YEL002c/WBP1_at  AFFX-YEL018w/_at  \\\n",
              "0         1.962483              1.919590          2.034229   \n",
              "1         2.054990              1.970140          1.768459   \n",
              "2         1.955286              1.768858          1.666836   \n",
              "3         2.363843              2.194837          1.981020   \n",
              "4         2.323899              2.288732          2.772796   \n",
              "5         2.172953              1.635655          1.885491   \n",
              "6         2.359402              2.495400          2.365220   \n",
              "7         2.354630              2.256550          2.220849   \n",
              "8         2.543716              2.483545          2.353530   \n",
              "9         2.228590              2.063278          2.016133   \n",
              "\n",
              "   AFFX-YEL021w/URA3_at  AFFX-YEL024w/RIP1_at  \n",
              "0              3.013061              2.208421  \n",
              "1              4.701207              2.513560  \n",
              "2              3.115166              2.136760  \n",
              "3              3.141350              2.550041  \n",
              "4              2.848256              2.803264  \n",
              "5              2.978715              2.603510  \n",
              "6              4.338475              3.266788  \n",
              "7              3.935853              2.800777  \n",
              "8              3.504419              2.823459  \n",
              "9              2.955133              2.590789  \n",
              "\n",
              "[10 rows x 12622 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c5347b8-8a86-449a-9c5d-d95c85e525ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>samples</th>\n",
              "      <th>type</th>\n",
              "      <th>41880_at</th>\n",
              "      <th>41881_at</th>\n",
              "      <th>41882_at</th>\n",
              "      <th>41883_at</th>\n",
              "      <th>41884_at</th>\n",
              "      <th>41885_at</th>\n",
              "      <th>41886_r_at</th>\n",
              "      <th>41887_at</th>\n",
              "      <th>...</th>\n",
              "      <th>AFFX-ThrX-3_at</th>\n",
              "      <th>AFFX-ThrX-5_at</th>\n",
              "      <th>AFFX-ThrX-M_at</th>\n",
              "      <th>AFFX-TrpnX-3_at</th>\n",
              "      <th>AFFX-TrpnX-5_at</th>\n",
              "      <th>AFFX-TrpnX-M_at</th>\n",
              "      <th>AFFX-YEL002c/WBP1_at</th>\n",
              "      <th>AFFX-YEL018w/_at</th>\n",
              "      <th>AFFX-YEL021w/URA3_at</th>\n",
              "      <th>AFFX-YEL024w/RIP1_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GSM152992.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.414076</td>\n",
              "      <td>4.113824</td>\n",
              "      <td>2.035911</td>\n",
              "      <td>3.102248</td>\n",
              "      <td>2.115578</td>\n",
              "      <td>1.775455</td>\n",
              "      <td>6.107839</td>\n",
              "      <td>2.160168</td>\n",
              "      <td>...</td>\n",
              "      <td>2.955998</td>\n",
              "      <td>2.910953</td>\n",
              "      <td>2.095267</td>\n",
              "      <td>1.617076</td>\n",
              "      <td>2.060144</td>\n",
              "      <td>1.962483</td>\n",
              "      <td>1.919590</td>\n",
              "      <td>2.034229</td>\n",
              "      <td>3.013061</td>\n",
              "      <td>2.208421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GSM152993.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.385157</td>\n",
              "      <td>4.078664</td>\n",
              "      <td>2.123064</td>\n",
              "      <td>3.087631</td>\n",
              "      <td>2.254190</td>\n",
              "      <td>1.815183</td>\n",
              "      <td>5.708878</td>\n",
              "      <td>2.134447</td>\n",
              "      <td>...</td>\n",
              "      <td>3.196521</td>\n",
              "      <td>2.975412</td>\n",
              "      <td>2.249950</td>\n",
              "      <td>1.757867</td>\n",
              "      <td>2.352185</td>\n",
              "      <td>2.054990</td>\n",
              "      <td>1.970140</td>\n",
              "      <td>1.768459</td>\n",
              "      <td>4.701207</td>\n",
              "      <td>2.513560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GSM152994.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.295522</td>\n",
              "      <td>4.085505</td>\n",
              "      <td>2.144344</td>\n",
              "      <td>3.071539</td>\n",
              "      <td>2.229422</td>\n",
              "      <td>1.985899</td>\n",
              "      <td>5.679248</td>\n",
              "      <td>2.100443</td>\n",
              "      <td>...</td>\n",
              "      <td>2.929904</td>\n",
              "      <td>2.857025</td>\n",
              "      <td>2.047436</td>\n",
              "      <td>1.625339</td>\n",
              "      <td>2.065674</td>\n",
              "      <td>1.955286</td>\n",
              "      <td>1.768858</td>\n",
              "      <td>1.666836</td>\n",
              "      <td>3.115166</td>\n",
              "      <td>2.136760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GSM152995.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.260478</td>\n",
              "      <td>4.466391</td>\n",
              "      <td>2.206410</td>\n",
              "      <td>3.505265</td>\n",
              "      <td>2.605014</td>\n",
              "      <td>1.887307</td>\n",
              "      <td>5.935039</td>\n",
              "      <td>2.261295</td>\n",
              "      <td>...</td>\n",
              "      <td>3.578538</td>\n",
              "      <td>3.420946</td>\n",
              "      <td>2.736342</td>\n",
              "      <td>1.940826</td>\n",
              "      <td>2.713500</td>\n",
              "      <td>2.363843</td>\n",
              "      <td>2.194837</td>\n",
              "      <td>1.981020</td>\n",
              "      <td>3.141350</td>\n",
              "      <td>2.550041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GSM152996.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.229731</td>\n",
              "      <td>4.291435</td>\n",
              "      <td>2.506255</td>\n",
              "      <td>3.220628</td>\n",
              "      <td>2.404673</td>\n",
              "      <td>1.886664</td>\n",
              "      <td>5.965917</td>\n",
              "      <td>2.274317</td>\n",
              "      <td>...</td>\n",
              "      <td>3.558184</td>\n",
              "      <td>3.083316</td>\n",
              "      <td>2.562048</td>\n",
              "      <td>1.923414</td>\n",
              "      <td>2.775842</td>\n",
              "      <td>2.323899</td>\n",
              "      <td>2.288732</td>\n",
              "      <td>2.772796</td>\n",
              "      <td>2.848256</td>\n",
              "      <td>2.803264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GSM152997.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.323719</td>\n",
              "      <td>4.042794</td>\n",
              "      <td>2.219460</td>\n",
              "      <td>3.030761</td>\n",
              "      <td>2.539964</td>\n",
              "      <td>1.836586</td>\n",
              "      <td>5.970438</td>\n",
              "      <td>1.880250</td>\n",
              "      <td>...</td>\n",
              "      <td>3.442099</td>\n",
              "      <td>3.239850</td>\n",
              "      <td>2.373556</td>\n",
              "      <td>1.973410</td>\n",
              "      <td>2.563835</td>\n",
              "      <td>2.172953</td>\n",
              "      <td>1.635655</td>\n",
              "      <td>1.885491</td>\n",
              "      <td>2.978715</td>\n",
              "      <td>2.603510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GSM152998.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.557032</td>\n",
              "      <td>4.196903</td>\n",
              "      <td>2.122405</td>\n",
              "      <td>3.495034</td>\n",
              "      <td>2.353686</td>\n",
              "      <td>2.100858</td>\n",
              "      <td>6.338756</td>\n",
              "      <td>2.019285</td>\n",
              "      <td>...</td>\n",
              "      <td>3.542867</td>\n",
              "      <td>3.178389</td>\n",
              "      <td>2.413796</td>\n",
              "      <td>2.038962</td>\n",
              "      <td>2.723099</td>\n",
              "      <td>2.359402</td>\n",
              "      <td>2.495400</td>\n",
              "      <td>2.365220</td>\n",
              "      <td>4.338475</td>\n",
              "      <td>3.266788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GSM152999.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.441765</td>\n",
              "      <td>4.148545</td>\n",
              "      <td>1.968985</td>\n",
              "      <td>3.230116</td>\n",
              "      <td>2.240704</td>\n",
              "      <td>1.896051</td>\n",
              "      <td>6.166129</td>\n",
              "      <td>2.012576</td>\n",
              "      <td>...</td>\n",
              "      <td>3.363998</td>\n",
              "      <td>3.314865</td>\n",
              "      <td>2.345718</td>\n",
              "      <td>1.927122</td>\n",
              "      <td>2.600874</td>\n",
              "      <td>2.354630</td>\n",
              "      <td>2.256550</td>\n",
              "      <td>2.220849</td>\n",
              "      <td>3.935853</td>\n",
              "      <td>2.800777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GSM153000.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.604707</td>\n",
              "      <td>4.234341</td>\n",
              "      <td>2.167552</td>\n",
              "      <td>3.394769</td>\n",
              "      <td>2.294088</td>\n",
              "      <td>2.089270</td>\n",
              "      <td>6.190621</td>\n",
              "      <td>2.030608</td>\n",
              "      <td>...</td>\n",
              "      <td>3.703331</td>\n",
              "      <td>3.263648</td>\n",
              "      <td>2.769345</td>\n",
              "      <td>2.183191</td>\n",
              "      <td>2.621211</td>\n",
              "      <td>2.543716</td>\n",
              "      <td>2.483545</td>\n",
              "      <td>2.353530</td>\n",
              "      <td>3.504419</td>\n",
              "      <td>2.823459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GSM153001.CEL</td>\n",
              "      <td>primary_prostate_tumor</td>\n",
              "      <td>2.364670</td>\n",
              "      <td>4.183144</td>\n",
              "      <td>1.866217</td>\n",
              "      <td>3.169024</td>\n",
              "      <td>2.371755</td>\n",
              "      <td>1.983816</td>\n",
              "      <td>5.748455</td>\n",
              "      <td>2.142535</td>\n",
              "      <td>...</td>\n",
              "      <td>3.077640</td>\n",
              "      <td>3.048728</td>\n",
              "      <td>2.230446</td>\n",
              "      <td>1.928804</td>\n",
              "      <td>2.466815</td>\n",
              "      <td>2.228590</td>\n",
              "      <td>2.063278</td>\n",
              "      <td>2.016133</td>\n",
              "      <td>2.955133</td>\n",
              "      <td>2.590789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã— 12622 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c5347b8-8a86-449a-9c5d-d95c85e525ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c5347b8-8a86-449a-9c5d-d95c85e525ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c5347b8-8a86-449a-9c5d-d95c85e525ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-289c5aac-9d71-427e-8a6f-d233b71214ac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-289c5aac-9d71-427e-8a6f-d233b71214ac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-289c5aac-9d71-427e-8a6f-d233b71214ac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(df.columns[[0, 1]], axis=1)\n",
        "y = df['type']"
      ],
      "metadata": {
        "id": "aQCODWGvpjRH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvTu93QYplse",
        "outputId": "6d42896e-1d56-49d7-cb62-0f4c68a47517"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding label menjadi angka menggunakan LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "n8blSMxGpo8D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagi data menjadi data pelatihan, validasi, dan pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# print(X_train.shape)"
      ],
      "metadata": {
        "id": "NVsIkRwfp1mz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalisasi data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)"
      ],
      "metadata": {
        "id": "GBGA47G6p7Lo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat DataFrame kosong untuk menyimpan hasil evaluasi\n",
        "results_df = pd.DataFrame(columns=['Optimizer', 'Hidden Layers', 'Validation Accuracy', 'Test Accuracy'])\n",
        "\n",
        "# Fungsi untuk menambahkan atau memperbarui nilai dalam DataFrame\n",
        "def update_results(optimizer, hidden_layers, val_acc, test_acc):\n",
        "    global results_df\n",
        "    # Mencari baris yang sesuai dengan kombinasi optimizer dan hidden layers\n",
        "    mask = (results_df['Optimizer'] == optimizer) & (results_df['Hidden Layers'] == hidden_layers)\n",
        "    # Jika kombinasi sudah ada, update nilai\n",
        "    if mask.any():\n",
        "        results_df.loc[mask, ['Validation Accuracy', 'Test Accuracy']] = val_acc, test_acc\n",
        "    # Jika kombinasi belum ada, tambahkan baris baru\n",
        "    else:\n",
        "        results_df = pd.concat([results_df, pd.DataFrame({'Optimizer': [optimizer],\n",
        "                                                          'Hidden Layers': [hidden_layers],\n",
        "                                                          'Validation Accuracy': [val_acc],\n",
        "                                                          'Test Accuracy': [test_acc]})],\n",
        "                                ignore_index=True)"
      ],
      "metadata": {
        "id": "CZHGWpsvmA6A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DNN with 1 Hidden Layer 1000 Neuron and Relu Activation"
      ],
      "metadata": {
        "id": "g4647rE3qA2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build the DNN model with one hidden layer\n",
        "def build_model_one_hidden():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(1000, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Hidden layer with 1000 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')          # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "wCssAxasqCDJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DNN with 2 Hidden Layer 500 Neuron and Relu Activation"
      ],
      "metadata": {
        "id": "xAP0arySqv_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build the DNN model with two hidden layer\n",
        "def build_model_two_hidden():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(500, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # 1st hidden layer with 500 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(500, activation='relu'),                                   # 2nd hidden layer with 500 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')         # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "8oUl8cFnqyI1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DNN with 3 Hidden Layer 250 Neuron and Relu Activation"
      ],
      "metadata": {
        "id": "t58L64LfqJ_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build the DNN model with three hidden layer\n",
        "def build_model_three_hidden():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(250, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # First hidden layer with 250 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(250, activation='relu'),                                   # Second hidden layer with 250 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(250, activation='relu'),                                   # Third hidden layer with 250 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')         # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "QZ9bviDJqKtE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DNN with 4 Hidden Layer 100 Neuron and Relu Activation"
      ],
      "metadata": {
        "id": "Tiad0rJSqUSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build the DNN model with four hidden layer\n",
        "def build_model_four_hidden():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # First hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(100, activation='relu'),                                   # Second hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(100, activation='relu'),                                   # Third hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(100, activation='relu'),                                   # Fourth hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')         # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "JvCg7eIdqU0T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the DNN model\n",
        "model_one_hidden_layer = build_model_one_hidden()\n",
        "model_two_hidden_layer = build_model_two_hidden()\n",
        "model_three_hidden_layer = build_model_three_hidden()\n",
        "model_four_hidden_layer = build_model_four_hidden()"
      ],
      "metadata": {
        "id": "ZoLHmPLgqdl2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGD Optimizer"
      ],
      "metadata": {
        "id": "mtWZHqXpq8Qv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 1 hidden Layer"
      ],
      "metadata": {
        "id": "U3LHpZyoq-hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "# optimizer_sgd = tf.keras.optimizers.SGD(learning_rate=0.01)  # Define the optimizer with learning rate\n",
        "model_one_hidden_layer.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_one_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvXQ6gdTrAha",
        "outputId": "a8a47eb5-084a-4b9e-f617-acced478a829"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 2s 154ms/step - loss: 1.6133 - accuracy: 0.5443 - val_loss: 1.8351 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 0.3069 - accuracy: 0.9114 - val_loss: 1.3945 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.3996 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4008 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4026 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4043 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4059 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 105ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4076 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 9.4703e-04 - accuracy: 1.0000 - val_loss: 1.4092 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 128ms/step - loss: 8.7932e-04 - accuracy: 1.0000 - val_loss: 1.4109 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 8.2267e-04 - accuracy: 1.0000 - val_loss: 1.4125 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 129ms/step - loss: 7.7546e-04 - accuracy: 1.0000 - val_loss: 1.4140 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 7.3302e-04 - accuracy: 1.0000 - val_loss: 1.4156 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 6.9716e-04 - accuracy: 1.0000 - val_loss: 1.4171 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 6.6587e-04 - accuracy: 1.0000 - val_loss: 1.4187 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 6.3765e-04 - accuracy: 1.0000 - val_loss: 1.4201 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 6.1231e-04 - accuracy: 1.0000 - val_loss: 1.4215 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 1s 59ms/step - loss: 5.8875e-04 - accuracy: 1.0000 - val_loss: 1.4230 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 5.6721e-04 - accuracy: 1.0000 - val_loss: 1.4246 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 5.4851e-04 - accuracy: 1.0000 - val_loss: 1.4260 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 5.3030e-04 - accuracy: 1.0000 - val_loss: 1.4274 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 5.1422e-04 - accuracy: 1.0000 - val_loss: 1.4289 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 4.9865e-04 - accuracy: 1.0000 - val_loss: 1.4303 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 4.8410e-04 - accuracy: 1.0000 - val_loss: 1.4317 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 4.7084e-04 - accuracy: 1.0000 - val_loss: 1.4330 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 4.5845e-04 - accuracy: 1.0000 - val_loss: 1.4344 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 4.4663e-04 - accuracy: 1.0000 - val_loss: 1.4357 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 4.3600e-04 - accuracy: 1.0000 - val_loss: 1.4369 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 4.2500e-04 - accuracy: 1.0000 - val_loss: 1.4381 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 4.1540e-04 - accuracy: 1.0000 - val_loss: 1.4394 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 4.0611e-04 - accuracy: 1.0000 - val_loss: 1.4405 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 3.9737e-04 - accuracy: 1.0000 - val_loss: 1.4418 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 3.8896e-04 - accuracy: 1.0000 - val_loss: 1.4429 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 3.8083e-04 - accuracy: 1.0000 - val_loss: 1.4441 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 3.7365e-04 - accuracy: 1.0000 - val_loss: 1.4453 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.6639e-04 - accuracy: 1.0000 - val_loss: 1.4464 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 3.5899e-04 - accuracy: 1.0000 - val_loss: 1.4475 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.5265e-04 - accuracy: 1.0000 - val_loss: 1.4487 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 3.4612e-04 - accuracy: 1.0000 - val_loss: 1.4498 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.3982e-04 - accuracy: 1.0000 - val_loss: 1.4508 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.3378e-04 - accuracy: 1.0000 - val_loss: 1.4519 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.2823e-04 - accuracy: 1.0000 - val_loss: 1.4529 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.2278e-04 - accuracy: 1.0000 - val_loss: 1.4540 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.1746e-04 - accuracy: 1.0000 - val_loss: 1.4550 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.1257e-04 - accuracy: 1.0000 - val_loss: 1.4560 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.0761e-04 - accuracy: 1.0000 - val_loss: 1.4570 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.0301e-04 - accuracy: 1.0000 - val_loss: 1.4580 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.9837e-04 - accuracy: 1.0000 - val_loss: 1.4590 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.9405e-04 - accuracy: 1.0000 - val_loss: 1.4600 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.8980e-04 - accuracy: 1.0000 - val_loss: 1.4608 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.8566e-04 - accuracy: 1.0000 - val_loss: 1.4618 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.8165e-04 - accuracy: 1.0000 - val_loss: 1.4627 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.7779e-04 - accuracy: 1.0000 - val_loss: 1.4637 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.7395e-04 - accuracy: 1.0000 - val_loss: 1.4646 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.7039e-04 - accuracy: 1.0000 - val_loss: 1.4654 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 2.6685e-04 - accuracy: 1.0000 - val_loss: 1.4663 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.6323e-04 - accuracy: 1.0000 - val_loss: 1.4671 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.5998e-04 - accuracy: 1.0000 - val_loss: 1.4680 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.5681e-04 - accuracy: 1.0000 - val_loss: 1.4689 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 2.5362e-04 - accuracy: 1.0000 - val_loss: 1.4697 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.5051e-04 - accuracy: 1.0000 - val_loss: 1.4706 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.4752e-04 - accuracy: 1.0000 - val_loss: 1.4714 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.4462e-04 - accuracy: 1.0000 - val_loss: 1.4722 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.4190e-04 - accuracy: 1.0000 - val_loss: 1.4730 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 2.3900e-04 - accuracy: 1.0000 - val_loss: 1.4738 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 2.3627e-04 - accuracy: 1.0000 - val_loss: 1.4746 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 2.3364e-04 - accuracy: 1.0000 - val_loss: 1.4755 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 2.3103e-04 - accuracy: 1.0000 - val_loss: 1.4762 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 2.2859e-04 - accuracy: 1.0000 - val_loss: 1.4770 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.2609e-04 - accuracy: 1.0000 - val_loss: 1.4778 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 2.2374e-04 - accuracy: 1.0000 - val_loss: 1.4786 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.2145e-04 - accuracy: 1.0000 - val_loss: 1.4793 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.1915e-04 - accuracy: 1.0000 - val_loss: 1.4800 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.1682e-04 - accuracy: 1.0000 - val_loss: 1.4808 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.1464e-04 - accuracy: 1.0000 - val_loss: 1.4816 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.1253e-04 - accuracy: 1.0000 - val_loss: 1.4823 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 2.1041e-04 - accuracy: 1.0000 - val_loss: 1.4830 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.0838e-04 - accuracy: 1.0000 - val_loss: 1.4837 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.0637e-04 - accuracy: 1.0000 - val_loss: 1.4844 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.0445e-04 - accuracy: 1.0000 - val_loss: 1.4851 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.0254e-04 - accuracy: 1.0000 - val_loss: 1.4858 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.0062e-04 - accuracy: 1.0000 - val_loss: 1.4865 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.9876e-04 - accuracy: 1.0000 - val_loss: 1.4872 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.9691e-04 - accuracy: 1.0000 - val_loss: 1.4878 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.9519e-04 - accuracy: 1.0000 - val_loss: 1.4885 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.9346e-04 - accuracy: 1.0000 - val_loss: 1.4892 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.9174e-04 - accuracy: 1.0000 - val_loss: 1.4898 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.9004e-04 - accuracy: 1.0000 - val_loss: 1.4905 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.8843e-04 - accuracy: 1.0000 - val_loss: 1.4912 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.8676e-04 - accuracy: 1.0000 - val_loss: 1.4918 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.8522e-04 - accuracy: 1.0000 - val_loss: 1.4924 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.8367e-04 - accuracy: 1.0000 - val_loss: 1.4930 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.8218e-04 - accuracy: 1.0000 - val_loss: 1.4936 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.8062e-04 - accuracy: 1.0000 - val_loss: 1.4943 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.7916e-04 - accuracy: 1.0000 - val_loss: 1.4949 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.7772e-04 - accuracy: 1.0000 - val_loss: 1.4955 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.7633e-04 - accuracy: 1.0000 - val_loss: 1.4961 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.7496e-04 - accuracy: 1.0000 - val_loss: 1.4967 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 1.7356e-04 - accuracy: 1.0000 - val_loss: 1.4973 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.7227e-04 - accuracy: 1.0000 - val_loss: 1.4979 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ambil loss dari history\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "IAeB-djPsS_1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot kurva loss\n",
        "plt.plot(epochs, train_loss, 'g', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "BedSLfcTUkme",
        "outputId": "676c923f-ae10-4c3b-8688-8ead052dda85"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_one_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_one_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAlFG684Vg7Q",
        "outputId": "2d1ba009-7dda-40fd-9cb5-aebc0541a9f2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 137ms/step - loss: 1.4979 - accuracy: 0.7000\n",
            "Model Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.5903 - accuracy: 0.7600\n",
            "Best Model Test Accuracy: 0.7599999904632568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('SGD', 1, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gAunOFmPCS",
        "outputId": "3e2956e9-7b65-49fb-9b4b-5688c65c8bb5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                  0.7           0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 2 hidden Layer"
      ],
      "metadata": {
        "id": "yCPOe4QYtr0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_two_hidden_layer.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_two_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhJ6YMkTtsYE",
        "outputId": "6e9e7d5c-6ac5-48ec-9c2d-2c235dd2be5b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 34ms/step - loss: 0.7460 - accuracy: 0.6329 - val_loss: 0.6685 - val_accuracy: 0.6500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0679 - accuracy: 0.9873 - val_loss: 0.6095 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.6381 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.6473 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.6553 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.6681 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6773 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6996 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7214 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7319 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7343 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7363 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7387 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7408 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7429 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7451 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7491 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7509 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7529 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7603 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7621 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7671 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7701 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7716 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7731 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7746 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7760 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7776 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7789 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7804 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7817 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7830 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7844 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7856 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7869 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7883 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7920 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7933 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7957 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8025 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8035 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9.9910e-04 - accuracy: 1.0000 - val_loss: 0.8068 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9.8537e-04 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9.7192e-04 - accuracy: 1.0000 - val_loss: 0.8088 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9.5903e-04 - accuracy: 1.0000 - val_loss: 0.8099 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9.4619e-04 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9.3378e-04 - accuracy: 1.0000 - val_loss: 0.8118 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9.2133e-04 - accuracy: 1.0000 - val_loss: 0.8128 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9.0928e-04 - accuracy: 1.0000 - val_loss: 0.8138 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.9811e-04 - accuracy: 1.0000 - val_loss: 0.8147 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8.8645e-04 - accuracy: 1.0000 - val_loss: 0.8157 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.7539e-04 - accuracy: 1.0000 - val_loss: 0.8167 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8.6493e-04 - accuracy: 1.0000 - val_loss: 0.8176 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8.5422e-04 - accuracy: 1.0000 - val_loss: 0.8185 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.4400e-04 - accuracy: 1.0000 - val_loss: 0.8194 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8.3376e-04 - accuracy: 1.0000 - val_loss: 0.8202 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8.2405e-04 - accuracy: 1.0000 - val_loss: 0.8211 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 8.1448e-04 - accuracy: 1.0000 - val_loss: 0.8221 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8.0527e-04 - accuracy: 1.0000 - val_loss: 0.8230 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.9583e-04 - accuracy: 1.0000 - val_loss: 0.8239 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.8700e-04 - accuracy: 1.0000 - val_loss: 0.8247 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.7816e-04 - accuracy: 1.0000 - val_loss: 0.8256 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.6956e-04 - accuracy: 1.0000 - val_loss: 0.8265 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.6123e-04 - accuracy: 1.0000 - val_loss: 0.8272 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 7.5276e-04 - accuracy: 1.0000 - val_loss: 0.8280 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4461e-04 - accuracy: 1.0000 - val_loss: 0.8289 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.3667e-04 - accuracy: 1.0000 - val_loss: 0.8297 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ambil loss dari history\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(train_loss) + 1)"
      ],
      "metadata": {
        "id": "U9mz3XslyAlU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot kurva loss\n",
        "plt.plot(epochs, train_loss, 'g', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "SA4RYiRkyD-E",
        "outputId": "77384b2d-32dc-476c-8ef1-156c57c48835"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_two_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 2 Hidden Layer SGD Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# 5. Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_two_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# 6. Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4YlOKSMyJ3_",
        "outputId": "7009313c-6ef0-41dd-f997-fa3fdd8f776b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 103ms/step - loss: 0.8297 - accuracy: 0.7000\n",
            "Model 2 Hidden Layer SGD Optimizer Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.4909 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('SGD', 2, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xadhxzGpmcjO",
        "outputId": "f84efa15-4d11-4d0a-d12b-b9b9dbf19023"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                  0.7           0.76\n",
            "1       SGD             2                  0.7           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 3 hidden Layer"
      ],
      "metadata": {
        "id": "DIVSqdm9yWdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_three_hidden_layer.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_three_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJCNzfvLyY28",
        "outputId": "de9435d3-ab6f-4b09-bae2-3e34aac0cf2a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 38ms/step - loss: 0.7965 - accuracy: 0.5190 - val_loss: 0.5657 - val_accuracy: 0.6500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1586 - accuracy: 0.9873 - val_loss: 0.5582 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0729 - accuracy: 1.0000 - val_loss: 0.5687 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.5773 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.5809 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.5898 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.5988 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.6261 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.6311 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.6373 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.6436 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.6487 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.6548 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.6645 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6688 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7059 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7195 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7259 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7320 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7407 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7433 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7458 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7586 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7654 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7678 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7698 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7722 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7741 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7762 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7782 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7804 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7824 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7844 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7864 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7882 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7919 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7938 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7956 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8026 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8045 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8062 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8095 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8110 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8127 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8142 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8159 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8174 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8189 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8205 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8222 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8235 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8250 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8265 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8280 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8294 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8309 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8323 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8336 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8351 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8366 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8380 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8394 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8406 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8420 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 9.9108e-04 - accuracy: 1.0000 - val_loss: 0.8432 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 9.7808e-04 - accuracy: 1.0000 - val_loss: 0.8446 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 9.6586e-04 - accuracy: 1.0000 - val_loss: 0.8459 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 9.5332e-04 - accuracy: 1.0000 - val_loss: 0.8471 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 9.4126e-04 - accuracy: 1.0000 - val_loss: 0.8484 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 9.2993e-04 - accuracy: 1.0000 - val_loss: 0.8497 - val_accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_three_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer SGD Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_three_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGxkomxAyrgV",
        "outputId": "6b1064d2-2396-4056-f931-0a7bcf3bc5f3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step - loss: 0.8497 - accuracy: 0.7500\n",
            "Model 3 Hidden Layer SGD Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.5354 - accuracy: 0.6800\n",
            "Best Model Test Accuracy: 0.6800000071525574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('SGD', 3, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AUn7KhOmk06",
        "outputId": "a4601f3e-fe5b-4a36-f63f-f1efd602eb17"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.70           0.76\n",
            "1       SGD             2                 0.70           0.60\n",
            "2       SGD             3                 0.75           0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 4 hidden Layer"
      ],
      "metadata": {
        "id": "BB6c--fUy36r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_four_hidden_layer.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_four_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQOI7pOty61V",
        "outputId": "f56e15db-2077-4cf3-b97b-619275e33bf0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 28ms/step - loss: 0.6765 - accuracy: 0.5823 - val_loss: 0.5917 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3293 - accuracy: 0.9873 - val_loss: 0.5530 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2042 - accuracy: 1.0000 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1387 - accuracy: 1.0000 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1007 - accuracy: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.5352 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.5538 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.5729 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.5933 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.6110 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.6188 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.6364 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.6439 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.6586 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.6659 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.6738 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6927 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.7217 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7319 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7373 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7414 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7468 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7512 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7596 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7637 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7676 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7721 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7760 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7836 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7871 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7905 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8006 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8068 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8100 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8131 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8160 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8191 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8221 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8247 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8277 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8301 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8330 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8355 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8381 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8405 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8430 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8454 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8479 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8504 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8525 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8550 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8572 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8592 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8615 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8684 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8704 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8725 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8766 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8787 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8804 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8825 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8861 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.9950e-04 - accuracy: 1.0000 - val_loss: 0.8879 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.8348e-04 - accuracy: 1.0000 - val_loss: 0.8899 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.6731e-04 - accuracy: 1.0000 - val_loss: 0.8915 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.5191e-04 - accuracy: 1.0000 - val_loss: 0.8935 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.3705e-04 - accuracy: 1.0000 - val_loss: 0.8951 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 9.2257e-04 - accuracy: 1.0000 - val_loss: 0.8968 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.0834e-04 - accuracy: 1.0000 - val_loss: 0.8986 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.9461e-04 - accuracy: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8113e-04 - accuracy: 1.0000 - val_loss: 0.9018 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.6804e-04 - accuracy: 1.0000 - val_loss: 0.9034 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.5520e-04 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.4298e-04 - accuracy: 1.0000 - val_loss: 0.9066 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.3072e-04 - accuracy: 1.0000 - val_loss: 0.9082 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.1898e-04 - accuracy: 1.0000 - val_loss: 0.9097 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.0753e-04 - accuracy: 1.0000 - val_loss: 0.9112 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.9622e-04 - accuracy: 1.0000 - val_loss: 0.9128 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_four_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer SGD Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_four_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36rrp5yhzEcA",
        "outputId": "a187e9e3-85d0-4acd-bfc6-d28c3e1ef61e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 106ms/step - loss: 0.9128 - accuracy: 0.7000\n",
            "Model 3 Hidden Layer SGD Optimizer Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.5719 - accuracy: 0.5200\n",
            "Best Model Test Accuracy: 0.5199999809265137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('SGD', 4, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRzFcqnXmshC",
        "outputId": "23a16592-13a8-4945-e7c2-83701ade89cb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.70           0.76\n",
            "1       SGD             2                 0.70           0.60\n",
            "2       SGD             3                 0.75           0.68\n",
            "3       SGD             4                 0.70           0.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adam Optimizer"
      ],
      "metadata": {
        "id": "jtsGTG8N2opl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 1 hidden Layer with Adam Optimizer"
      ],
      "metadata": {
        "id": "Kcdu_-RB2q4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "# optimizer_adam = tf.keras.optimizers.Adam(learning_rate=0.001)  # Define the optimizer with learning rate\n",
        "model_one_hidden_layer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_one_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sivm9xLk2tlF",
        "outputId": "42d3b987-fa21-4083-da67-7399f17ea862"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 130ms/step - loss: 5.4076 - accuracy: 0.6962 - val_loss: 9.6629 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 5.4742 - accuracy: 0.8228 - val_loss: 11.1155 - val_accuracy: 0.6500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 1.0444 - accuracy: 0.9114 - val_loss: 14.4273 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 0.1728 - accuracy: 0.9873 - val_loss: 17.1176 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 0.3341 - accuracy: 0.9747 - val_loss: 18.8256 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 4.1837e-06 - accuracy: 1.0000 - val_loss: 21.8398 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 0.0130 - accuracy: 0.9873 - val_loss: 21.4322 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 4.8287e-08 - accuracy: 1.0000 - val_loss: 20.6763 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 1.9617e-08 - accuracy: 1.0000 - val_loss: 20.5010 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.6417 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7071 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7370 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7504 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7564 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7591 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 174ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7609 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7613 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7613 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7613 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 1s 143ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 1s 160ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 176ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 1s 139ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 1s 163ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7610 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7610 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7610 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7610 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7610 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7610 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7610 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7610 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7609 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7609 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7609 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7609 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7609 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 149ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7609 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7609 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7609 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7609 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7608 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7608 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7608 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7608 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7608 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7608 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 133ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7608 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 178ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7607 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7607 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7607 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7607 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7607 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7607 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7606 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7606 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7606 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7606 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7606 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 1s 195ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7606 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7605 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7605 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7605 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7605 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7605 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 1s 126ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7605 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7604 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7604 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7604 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7604 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7604 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 136ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7604 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_one_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 1 Hidden Layer Adam Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_one_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw5LBLti4iqd",
        "outputId": "be0860d1-70cb-4577-d069-87b518b1c78c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 106ms/step - loss: 20.7603 - accuracy: 0.7000\n",
            "Model 1 Hidden Layer Adam Optimizer Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 3.0400 - accuracy: 0.6800\n",
            "Best Model Test Accuracy: 0.6800000071525574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('ADAM', 1, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_VrN6DSmzjn",
        "outputId": "fa956d43-a4c1-403b-b6ed-1f429b6ee4d0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.70           0.76\n",
            "1       SGD             2                 0.70           0.60\n",
            "2       SGD             3                 0.75           0.68\n",
            "3       SGD             4                 0.70           0.52\n",
            "4      ADAM             1                 0.70           0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 2 hidden Layer with Adam Optimizer"
      ],
      "metadata": {
        "id": "Pr-KfD3n4sI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_two_hidden_layer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_two_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHML5eST4uf8",
        "outputId": "fa9cfdc7-be9c-4745-943e-89013bc76c70"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 62ms/step - loss: 2.4851 - accuracy: 0.6962 - val_loss: 4.2102 - val_accuracy: 0.5500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 3.3786 - accuracy: 0.8101 - val_loss: 4.8779 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.5216 - accuracy: 0.9114 - val_loss: 7.9872 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.5318 - accuracy: 0.9367 - val_loss: 6.2983 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.5181 - accuracy: 0.9367 - val_loss: 11.2620 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1399 - accuracy: 0.9747 - val_loss: 12.6989 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.1015 - accuracy: 0.9747 - val_loss: 11.2850 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 11.6168 - val_accuracy: 0.6500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 9.1416e-05 - accuracy: 1.0000 - val_loss: 11.0493 - val_accuracy: 0.6500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 6.4896e-04 - accuracy: 1.0000 - val_loss: 10.5740 - val_accuracy: 0.6500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 3.2821e-05 - accuracy: 1.0000 - val_loss: 10.3106 - val_accuracy: 0.6500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 2.1424e-05 - accuracy: 1.0000 - val_loss: 10.1960 - val_accuracy: 0.6500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 1.8970e-05 - accuracy: 1.0000 - val_loss: 10.1472 - val_accuracy: 0.6500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.5845e-05 - accuracy: 1.0000 - val_loss: 10.1300 - val_accuracy: 0.6500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.2770e-05 - accuracy: 1.0000 - val_loss: 10.1264 - val_accuracy: 0.6500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 9.9949e-06 - accuracy: 1.0000 - val_loss: 10.1266 - val_accuracy: 0.6500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 8.1380e-06 - accuracy: 1.0000 - val_loss: 10.1276 - val_accuracy: 0.6500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 7.5286e-06 - accuracy: 1.0000 - val_loss: 10.1305 - val_accuracy: 0.6500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 6.4997e-06 - accuracy: 1.0000 - val_loss: 10.1325 - val_accuracy: 0.6500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 5.8858e-06 - accuracy: 1.0000 - val_loss: 10.1347 - val_accuracy: 0.6500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 5.3125e-06 - accuracy: 1.0000 - val_loss: 10.1365 - val_accuracy: 0.6500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 4.9097e-06 - accuracy: 1.0000 - val_loss: 10.1379 - val_accuracy: 0.6500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 4.5687e-06 - accuracy: 1.0000 - val_loss: 10.1396 - val_accuracy: 0.6500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 4.3032e-06 - accuracy: 1.0000 - val_loss: 10.1413 - val_accuracy: 0.6500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 3.9305e-06 - accuracy: 1.0000 - val_loss: 10.1426 - val_accuracy: 0.6500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 3.7148e-06 - accuracy: 1.0000 - val_loss: 10.1439 - val_accuracy: 0.6500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 3.4975e-06 - accuracy: 1.0000 - val_loss: 10.1453 - val_accuracy: 0.6500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 3.3089e-06 - accuracy: 1.0000 - val_loss: 10.1464 - val_accuracy: 0.6500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 3.0630e-06 - accuracy: 1.0000 - val_loss: 10.1472 - val_accuracy: 0.6500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 2.9136e-06 - accuracy: 1.0000 - val_loss: 10.1483 - val_accuracy: 0.6500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.7733e-06 - accuracy: 1.0000 - val_loss: 10.1496 - val_accuracy: 0.6500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 2.6451e-06 - accuracy: 1.0000 - val_loss: 10.1507 - val_accuracy: 0.6500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.4897e-06 - accuracy: 1.0000 - val_loss: 10.1514 - val_accuracy: 0.6500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 2.4293e-06 - accuracy: 1.0000 - val_loss: 10.1525 - val_accuracy: 0.6500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.2845e-06 - accuracy: 1.0000 - val_loss: 10.1534 - val_accuracy: 0.6500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 2.1834e-06 - accuracy: 1.0000 - val_loss: 10.1543 - val_accuracy: 0.6500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 2.0853e-06 - accuracy: 1.0000 - val_loss: 10.1551 - val_accuracy: 0.6500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.0280e-06 - accuracy: 1.0000 - val_loss: 10.1559 - val_accuracy: 0.6500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.9359e-06 - accuracy: 1.0000 - val_loss: 10.1569 - val_accuracy: 0.6500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.8439e-06 - accuracy: 1.0000 - val_loss: 10.1576 - val_accuracy: 0.6500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.7760e-06 - accuracy: 1.0000 - val_loss: 10.1585 - val_accuracy: 0.6500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.7156e-06 - accuracy: 1.0000 - val_loss: 10.1594 - val_accuracy: 0.6500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.6628e-06 - accuracy: 1.0000 - val_loss: 10.1603 - val_accuracy: 0.6500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.5904e-06 - accuracy: 1.0000 - val_loss: 10.1609 - val_accuracy: 0.6500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.5346e-06 - accuracy: 1.0000 - val_loss: 10.1617 - val_accuracy: 0.6500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.5195e-06 - accuracy: 1.0000 - val_loss: 10.1627 - val_accuracy: 0.6500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4425e-06 - accuracy: 1.0000 - val_loss: 10.1635 - val_accuracy: 0.6500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.3958e-06 - accuracy: 1.0000 - val_loss: 10.1642 - val_accuracy: 0.6500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.3399e-06 - accuracy: 1.0000 - val_loss: 10.1648 - val_accuracy: 0.6500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.3173e-06 - accuracy: 1.0000 - val_loss: 10.1657 - val_accuracy: 0.6500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.2705e-06 - accuracy: 1.0000 - val_loss: 10.1664 - val_accuracy: 0.6500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.2283e-06 - accuracy: 1.0000 - val_loss: 10.1670 - val_accuracy: 0.6500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.1951e-06 - accuracy: 1.0000 - val_loss: 10.1676 - val_accuracy: 0.6500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 1.1574e-06 - accuracy: 1.0000 - val_loss: 10.1682 - val_accuracy: 0.6500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 1.1287e-06 - accuracy: 1.0000 - val_loss: 10.1688 - val_accuracy: 0.6500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 1.1061e-06 - accuracy: 1.0000 - val_loss: 10.1694 - val_accuracy: 0.6500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.0729e-06 - accuracy: 1.0000 - val_loss: 10.1701 - val_accuracy: 0.6500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.0397e-06 - accuracy: 1.0000 - val_loss: 10.1707 - val_accuracy: 0.6500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.0246e-06 - accuracy: 1.0000 - val_loss: 10.1713 - val_accuracy: 0.6500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 9.8987e-07 - accuracy: 1.0000 - val_loss: 10.1719 - val_accuracy: 0.6500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 9.6422e-07 - accuracy: 1.0000 - val_loss: 10.1725 - val_accuracy: 0.6500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 9.4460e-07 - accuracy: 1.0000 - val_loss: 10.1731 - val_accuracy: 0.6500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 9.2347e-07 - accuracy: 1.0000 - val_loss: 10.1737 - val_accuracy: 0.6500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 8.9028e-07 - accuracy: 1.0000 - val_loss: 10.1741 - val_accuracy: 0.6500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 8.7972e-07 - accuracy: 1.0000 - val_loss: 10.1746 - val_accuracy: 0.6500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 8.5557e-07 - accuracy: 1.0000 - val_loss: 10.1752 - val_accuracy: 0.6500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 8.3294e-07 - accuracy: 1.0000 - val_loss: 10.1757 - val_accuracy: 0.6500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 8.1634e-07 - accuracy: 1.0000 - val_loss: 10.1762 - val_accuracy: 0.6500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 7.9673e-07 - accuracy: 1.0000 - val_loss: 10.1768 - val_accuracy: 0.6500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 7.8315e-07 - accuracy: 1.0000 - val_loss: 10.1774 - val_accuracy: 0.6500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 7.6504e-07 - accuracy: 1.0000 - val_loss: 10.1779 - val_accuracy: 0.6500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 7.4844e-07 - accuracy: 1.0000 - val_loss: 10.1784 - val_accuracy: 0.6500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 7.2581e-07 - accuracy: 1.0000 - val_loss: 10.1788 - val_accuracy: 0.6500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 7.1223e-07 - accuracy: 1.0000 - val_loss: 10.1793 - val_accuracy: 0.6500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 6.9714e-07 - accuracy: 1.0000 - val_loss: 10.1797 - val_accuracy: 0.6500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 6.8507e-07 - accuracy: 1.0000 - val_loss: 10.1802 - val_accuracy: 0.6500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 6.7148e-07 - accuracy: 1.0000 - val_loss: 10.1807 - val_accuracy: 0.6500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 6.5489e-07 - accuracy: 1.0000 - val_loss: 10.1812 - val_accuracy: 0.6500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 6.4282e-07 - accuracy: 1.0000 - val_loss: 10.1815 - val_accuracy: 0.6500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 6.3225e-07 - accuracy: 1.0000 - val_loss: 10.1821 - val_accuracy: 0.6500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 6.2018e-07 - accuracy: 1.0000 - val_loss: 10.1825 - val_accuracy: 0.6500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 6.0811e-07 - accuracy: 1.0000 - val_loss: 10.1830 - val_accuracy: 0.6500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 5.9302e-07 - accuracy: 1.0000 - val_loss: 10.1834 - val_accuracy: 0.6500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 5.8095e-07 - accuracy: 1.0000 - val_loss: 10.1838 - val_accuracy: 0.6500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 5.7491e-07 - accuracy: 1.0000 - val_loss: 10.1842 - val_accuracy: 0.6500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 5.6133e-07 - accuracy: 1.0000 - val_loss: 10.1847 - val_accuracy: 0.6500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 5.5077e-07 - accuracy: 1.0000 - val_loss: 10.1851 - val_accuracy: 0.6500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 5.4323e-07 - accuracy: 1.0000 - val_loss: 10.1855 - val_accuracy: 0.6500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 5.3568e-07 - accuracy: 1.0000 - val_loss: 10.1860 - val_accuracy: 0.6500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 5.2512e-07 - accuracy: 1.0000 - val_loss: 10.1865 - val_accuracy: 0.6500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 5.1456e-07 - accuracy: 1.0000 - val_loss: 10.1869 - val_accuracy: 0.6500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 5.0399e-07 - accuracy: 1.0000 - val_loss: 10.1873 - val_accuracy: 0.6500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 4.9796e-07 - accuracy: 1.0000 - val_loss: 10.1876 - val_accuracy: 0.6500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 4.9041e-07 - accuracy: 1.0000 - val_loss: 10.1881 - val_accuracy: 0.6500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 4.8136e-07 - accuracy: 1.0000 - val_loss: 10.1885 - val_accuracy: 0.6500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 4.7381e-07 - accuracy: 1.0000 - val_loss: 10.1889 - val_accuracy: 0.6500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 4.6627e-07 - accuracy: 1.0000 - val_loss: 10.1893 - val_accuracy: 0.6500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 4.5571e-07 - accuracy: 1.0000 - val_loss: 10.1896 - val_accuracy: 0.6500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 4.5118e-07 - accuracy: 1.0000 - val_loss: 10.1900 - val_accuracy: 0.6500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 4.4213e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_two_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 2 Hidden Layer Adam Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_two_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrS0LpCf578Z",
        "outputId": "89b5bdb7-dc8c-45a0-d59c-67ac2aedcfec"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step - loss: 10.1903 - accuracy: 0.6500\n",
            "Model 2 Hidden Layer Adam Optimizer Validation Accuracy: 0.6499999761581421\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 9.0989 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('ADAM', 2, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prVeza55nC9K",
        "outputId": "a5816c93-de48-432a-92ee-a75df926d07a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.70           0.76\n",
            "1       SGD             2                 0.70           0.60\n",
            "2       SGD             3                 0.75           0.68\n",
            "3       SGD             4                 0.70           0.52\n",
            "4      ADAM             1                 0.70           0.68\n",
            "5      ADAM             2                 0.65           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 3 hidden Layer with Adam Optimizer"
      ],
      "metadata": {
        "id": "xBco_lbK8_ON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_three_hidden_layer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_three_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIMeNscg9BlI",
        "outputId": "6b156930-8486-4ed0-b2fe-2c86c4f510bb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 36ms/step - loss: 1.1883 - accuracy: 0.7975 - val_loss: 2.6267 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.4797 - accuracy: 0.8608 - val_loss: 3.0994 - val_accuracy: 0.6500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.1185 - accuracy: 0.8354 - val_loss: 3.7809 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.4829 - accuracy: 0.9494 - val_loss: 2.3607 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0299 - accuracy: 0.9873 - val_loss: 2.3151 - val_accuracy: 0.8000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8.4646e-04 - accuracy: 1.0000 - val_loss: 2.5192 - val_accuracy: 0.8500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.6685e-05 - accuracy: 1.0000 - val_loss: 2.6937 - val_accuracy: 0.8000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 5.5620e-05 - accuracy: 1.0000 - val_loss: 2.8040 - val_accuracy: 0.8000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 3.8092e-05 - accuracy: 1.0000 - val_loss: 2.8592 - val_accuracy: 0.8000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.5533e-05 - accuracy: 1.0000 - val_loss: 2.8857 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.8777e-05 - accuracy: 1.0000 - val_loss: 2.8990 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.5943e-05 - accuracy: 1.0000 - val_loss: 2.9021 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.2974e-05 - accuracy: 1.0000 - val_loss: 2.9027 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1155e-05 - accuracy: 1.0000 - val_loss: 2.9026 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0378e-05 - accuracy: 1.0000 - val_loss: 2.9008 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 8.9776e-06 - accuracy: 1.0000 - val_loss: 2.9007 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 7.9743e-06 - accuracy: 1.0000 - val_loss: 2.9001 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 7.3648e-06 - accuracy: 1.0000 - val_loss: 2.9011 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 6.9679e-06 - accuracy: 1.0000 - val_loss: 2.9020 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 6.3056e-06 - accuracy: 1.0000 - val_loss: 2.9018 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 5.9601e-06 - accuracy: 1.0000 - val_loss: 2.9014 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 5.5995e-06 - accuracy: 1.0000 - val_loss: 2.9009 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 5.2676e-06 - accuracy: 1.0000 - val_loss: 2.9004 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 4.9055e-06 - accuracy: 1.0000 - val_loss: 2.9001 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 4.6972e-06 - accuracy: 1.0000 - val_loss: 2.8995 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 4.4785e-06 - accuracy: 1.0000 - val_loss: 2.8995 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 4.1616e-06 - accuracy: 1.0000 - val_loss: 2.9000 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.9217e-06 - accuracy: 1.0000 - val_loss: 2.9000 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.7059e-06 - accuracy: 1.0000 - val_loss: 2.9001 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.5656e-06 - accuracy: 1.0000 - val_loss: 2.9010 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 3.4313e-06 - accuracy: 1.0000 - val_loss: 2.9009 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.2608e-06 - accuracy: 1.0000 - val_loss: 2.9017 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 3.1582e-06 - accuracy: 1.0000 - val_loss: 2.9021 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.9952e-06 - accuracy: 1.0000 - val_loss: 2.9032 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.9213e-06 - accuracy: 1.0000 - val_loss: 2.9049 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.8127e-06 - accuracy: 1.0000 - val_loss: 2.9060 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.7010e-06 - accuracy: 1.0000 - val_loss: 2.9069 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.5984e-06 - accuracy: 1.0000 - val_loss: 2.9079 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.5411e-06 - accuracy: 1.0000 - val_loss: 2.9089 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.4385e-06 - accuracy: 1.0000 - val_loss: 2.9098 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.3706e-06 - accuracy: 1.0000 - val_loss: 2.9113 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.2936e-06 - accuracy: 1.0000 - val_loss: 2.9116 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.2197e-06 - accuracy: 1.0000 - val_loss: 2.9121 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.1684e-06 - accuracy: 1.0000 - val_loss: 2.9125 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.1050e-06 - accuracy: 1.0000 - val_loss: 2.9131 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.0416e-06 - accuracy: 1.0000 - val_loss: 2.9138 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.9828e-06 - accuracy: 1.0000 - val_loss: 2.9142 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.9330e-06 - accuracy: 1.0000 - val_loss: 2.9150 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.8786e-06 - accuracy: 1.0000 - val_loss: 2.9160 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.8439e-06 - accuracy: 1.0000 - val_loss: 2.9164 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.8062e-06 - accuracy: 1.0000 - val_loss: 2.9173 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.7428e-06 - accuracy: 1.0000 - val_loss: 2.9181 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.7081e-06 - accuracy: 1.0000 - val_loss: 2.9189 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.6674e-06 - accuracy: 1.0000 - val_loss: 2.9195 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.6282e-06 - accuracy: 1.0000 - val_loss: 2.9203 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5904e-06 - accuracy: 1.0000 - val_loss: 2.9214 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.5572e-06 - accuracy: 1.0000 - val_loss: 2.9227 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5225e-06 - accuracy: 1.0000 - val_loss: 2.9235 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.4924e-06 - accuracy: 1.0000 - val_loss: 2.9241 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4622e-06 - accuracy: 1.0000 - val_loss: 2.9244 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.4320e-06 - accuracy: 1.0000 - val_loss: 2.9245 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.3958e-06 - accuracy: 1.0000 - val_loss: 2.9256 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.3732e-06 - accuracy: 1.0000 - val_loss: 2.9266 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.3475e-06 - accuracy: 1.0000 - val_loss: 2.9269 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.3173e-06 - accuracy: 1.0000 - val_loss: 2.9274 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2932e-06 - accuracy: 1.0000 - val_loss: 2.9281 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2690e-06 - accuracy: 1.0000 - val_loss: 2.9284 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.2509e-06 - accuracy: 1.0000 - val_loss: 2.9288 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.2238e-06 - accuracy: 1.0000 - val_loss: 2.9290 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.2011e-06 - accuracy: 1.0000 - val_loss: 2.9295 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1800e-06 - accuracy: 1.0000 - val_loss: 2.9299 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1589e-06 - accuracy: 1.0000 - val_loss: 2.9305 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1347e-06 - accuracy: 1.0000 - val_loss: 2.9311 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.1242e-06 - accuracy: 1.0000 - val_loss: 2.9315 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.0985e-06 - accuracy: 1.0000 - val_loss: 2.9318 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.0774e-06 - accuracy: 1.0000 - val_loss: 2.9322 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.0668e-06 - accuracy: 1.0000 - val_loss: 2.9328 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.0457e-06 - accuracy: 1.0000 - val_loss: 2.9335 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0321e-06 - accuracy: 1.0000 - val_loss: 2.9337 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.0155e-06 - accuracy: 1.0000 - val_loss: 2.9342 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 9.9441e-07 - accuracy: 1.0000 - val_loss: 2.9347 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 9.8234e-07 - accuracy: 1.0000 - val_loss: 2.9352 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 9.6876e-07 - accuracy: 1.0000 - val_loss: 2.9357 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 9.4763e-07 - accuracy: 1.0000 - val_loss: 2.9360 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 9.3707e-07 - accuracy: 1.0000 - val_loss: 2.9364 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 9.1745e-07 - accuracy: 1.0000 - val_loss: 2.9370 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 9.0538e-07 - accuracy: 1.0000 - val_loss: 2.9374 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8.9029e-07 - accuracy: 1.0000 - val_loss: 2.9379 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8.7973e-07 - accuracy: 1.0000 - val_loss: 2.9384 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 8.6766e-07 - accuracy: 1.0000 - val_loss: 2.9388 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 8.5257e-07 - accuracy: 1.0000 - val_loss: 2.9390 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 8.4351e-07 - accuracy: 1.0000 - val_loss: 2.9395 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8.3144e-07 - accuracy: 1.0000 - val_loss: 2.9400 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 8.1786e-07 - accuracy: 1.0000 - val_loss: 2.9405 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 8.0881e-07 - accuracy: 1.0000 - val_loss: 2.9408 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 7.9825e-07 - accuracy: 1.0000 - val_loss: 2.9413 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.8617e-07 - accuracy: 1.0000 - val_loss: 2.9417 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 7.7259e-07 - accuracy: 1.0000 - val_loss: 2.9420 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 7.6505e-07 - accuracy: 1.0000 - val_loss: 2.9426 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 7.5449e-07 - accuracy: 1.0000 - val_loss: 2.9431 - val_accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_three_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer Adam Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_three_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXV8zs749Jkc",
        "outputId": "098a1234-9dc7-4706-e533-d4693b8b4115"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 114ms/step - loss: 2.9431 - accuracy: 0.7500\n",
            "Model 3 Hidden Layer Adam Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 19.9428 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('ADAM', 3, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wx0NbEZnPeA",
        "outputId": "e492b87b-9557-4d61-94ec-222858799b06"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.70           0.76\n",
            "1       SGD             2                 0.70           0.60\n",
            "2       SGD             3                 0.75           0.68\n",
            "3       SGD             4                 0.70           0.52\n",
            "4      ADAM             1                 0.70           0.68\n",
            "5      ADAM             2                 0.65           0.60\n",
            "6      ADAM             3                 0.75           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 4 hidden Layer with Adam Optimizer"
      ],
      "metadata": {
        "id": "PlMTpgBG9cO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_four_hidden_layer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_four_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCJ24UiW9eZe",
        "outputId": "cce909f4-1e59-44fc-d42c-6846fe234da4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 27ms/step - loss: 0.7121 - accuracy: 0.8354 - val_loss: 1.2140 - val_accuracy: 0.8000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8836 - accuracy: 0.8101 - val_loss: 2.1826 - val_accuracy: 0.6500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.2608 - accuracy: 0.9114 - val_loss: 2.5354 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1717 - accuracy: 0.9620 - val_loss: 2.8455 - val_accuracy: 0.6500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.5713 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0429 - accuracy: 0.9747 - val_loss: 3.0235 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.3810 - accuracy: 0.9747 - val_loss: 3.3553 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.2713 - val_accuracy: 0.6500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0652 - accuracy: 0.9873 - val_loss: 2.7983 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.2020e-04 - accuracy: 1.0000 - val_loss: 2.8044 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1283 - accuracy: 0.9873 - val_loss: 3.2678 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0448 - accuracy: 0.9620 - val_loss: 3.6342 - val_accuracy: 0.6500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 6.7376e-04 - accuracy: 1.0000 - val_loss: 3.4644 - val_accuracy: 0.6000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9873 - val_loss: 3.4161 - val_accuracy: 0.6000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.8833e-04 - accuracy: 1.0000 - val_loss: 3.4966 - val_accuracy: 0.6000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.7608e-04 - accuracy: 1.0000 - val_loss: 3.5114 - val_accuracy: 0.6000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.5617e-04 - accuracy: 1.0000 - val_loss: 3.5071 - val_accuracy: 0.6000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.1553e-04 - accuracy: 1.0000 - val_loss: 3.4955 - val_accuracy: 0.6000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.5630e-05 - accuracy: 1.0000 - val_loss: 3.4870 - val_accuracy: 0.6000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 7.4796e-05 - accuracy: 1.0000 - val_loss: 3.4791 - val_accuracy: 0.6000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.3486e-05 - accuracy: 1.0000 - val_loss: 3.4732 - val_accuracy: 0.6000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 5.7692e-05 - accuracy: 1.0000 - val_loss: 3.4692 - val_accuracy: 0.6000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 5.3834e-05 - accuracy: 1.0000 - val_loss: 3.4649 - val_accuracy: 0.6000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 5.0309e-05 - accuracy: 1.0000 - val_loss: 3.4614 - val_accuracy: 0.6000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 4.7425e-05 - accuracy: 1.0000 - val_loss: 3.4588 - val_accuracy: 0.6000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 4.4707e-05 - accuracy: 1.0000 - val_loss: 3.4566 - val_accuracy: 0.6000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 4.2500e-05 - accuracy: 1.0000 - val_loss: 3.4543 - val_accuracy: 0.6000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 4.0833e-05 - accuracy: 1.0000 - val_loss: 3.4509 - val_accuracy: 0.6000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 3.8500e-05 - accuracy: 1.0000 - val_loss: 3.4484 - val_accuracy: 0.6000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 3.6976e-05 - accuracy: 1.0000 - val_loss: 3.4465 - val_accuracy: 0.6000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 3.5448e-05 - accuracy: 1.0000 - val_loss: 3.4443 - val_accuracy: 0.6000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 3.4025e-05 - accuracy: 1.0000 - val_loss: 3.4430 - val_accuracy: 0.6000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.2891e-05 - accuracy: 1.0000 - val_loss: 3.4415 - val_accuracy: 0.6000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.1815e-05 - accuracy: 1.0000 - val_loss: 3.4401 - val_accuracy: 0.6000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.0777e-05 - accuracy: 1.0000 - val_loss: 3.4381 - val_accuracy: 0.6000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.9729e-05 - accuracy: 1.0000 - val_loss: 3.4369 - val_accuracy: 0.6000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 2.8996e-05 - accuracy: 1.0000 - val_loss: 3.4361 - val_accuracy: 0.6000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.7997e-05 - accuracy: 1.0000 - val_loss: 3.4355 - val_accuracy: 0.6000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.7255e-05 - accuracy: 1.0000 - val_loss: 3.4346 - val_accuracy: 0.6000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.6470e-05 - accuracy: 1.0000 - val_loss: 3.4340 - val_accuracy: 0.6000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.5828e-05 - accuracy: 1.0000 - val_loss: 3.4336 - val_accuracy: 0.6000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.5055e-05 - accuracy: 1.0000 - val_loss: 3.4332 - val_accuracy: 0.6000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 2.4464e-05 - accuracy: 1.0000 - val_loss: 3.4328 - val_accuracy: 0.6000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.3850e-05 - accuracy: 1.0000 - val_loss: 3.4324 - val_accuracy: 0.6000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.3272e-05 - accuracy: 1.0000 - val_loss: 3.4319 - val_accuracy: 0.6000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.2732e-05 - accuracy: 1.0000 - val_loss: 3.4317 - val_accuracy: 0.6000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.2180e-05 - accuracy: 1.0000 - val_loss: 3.4314 - val_accuracy: 0.6000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.1697e-05 - accuracy: 1.0000 - val_loss: 3.4312 - val_accuracy: 0.6000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.1183e-05 - accuracy: 1.0000 - val_loss: 3.4313 - val_accuracy: 0.6000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.0732e-05 - accuracy: 1.0000 - val_loss: 3.4316 - val_accuracy: 0.6000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 2.0256e-05 - accuracy: 1.0000 - val_loss: 3.4316 - val_accuracy: 0.6000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.9816e-05 - accuracy: 1.0000 - val_loss: 3.4316 - val_accuracy: 0.6000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.9407e-05 - accuracy: 1.0000 - val_loss: 3.4316 - val_accuracy: 0.6000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.9012e-05 - accuracy: 1.0000 - val_loss: 3.4320 - val_accuracy: 0.6000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.8603e-05 - accuracy: 1.0000 - val_loss: 3.4320 - val_accuracy: 0.6000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.8215e-05 - accuracy: 1.0000 - val_loss: 3.4322 - val_accuracy: 0.6000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.7885e-05 - accuracy: 1.0000 - val_loss: 3.4326 - val_accuracy: 0.6000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.7513e-05 - accuracy: 1.0000 - val_loss: 3.4326 - val_accuracy: 0.6000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.7185e-05 - accuracy: 1.0000 - val_loss: 3.4327 - val_accuracy: 0.6000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.6865e-05 - accuracy: 1.0000 - val_loss: 3.4329 - val_accuracy: 0.6000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.6510e-05 - accuracy: 1.0000 - val_loss: 3.4335 - val_accuracy: 0.6000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.6213e-05 - accuracy: 1.0000 - val_loss: 3.4334 - val_accuracy: 0.6000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.5911e-05 - accuracy: 1.0000 - val_loss: 3.4338 - val_accuracy: 0.6000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.5582e-05 - accuracy: 1.0000 - val_loss: 3.4341 - val_accuracy: 0.6000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.5338e-05 - accuracy: 1.0000 - val_loss: 3.4344 - val_accuracy: 0.6000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.5093e-05 - accuracy: 1.0000 - val_loss: 3.4349 - val_accuracy: 0.6000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.4748e-05 - accuracy: 1.0000 - val_loss: 3.4353 - val_accuracy: 0.6000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.4528e-05 - accuracy: 1.0000 - val_loss: 3.4357 - val_accuracy: 0.6000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.4248e-05 - accuracy: 1.0000 - val_loss: 3.4363 - val_accuracy: 0.6000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.3995e-05 - accuracy: 1.0000 - val_loss: 3.4366 - val_accuracy: 0.6000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.3735e-05 - accuracy: 1.0000 - val_loss: 3.4369 - val_accuracy: 0.6000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.3488e-05 - accuracy: 1.0000 - val_loss: 3.4373 - val_accuracy: 0.6000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.3283e-05 - accuracy: 1.0000 - val_loss: 3.4379 - val_accuracy: 0.6000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.3038e-05 - accuracy: 1.0000 - val_loss: 3.4382 - val_accuracy: 0.6000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.2824e-05 - accuracy: 1.0000 - val_loss: 3.4384 - val_accuracy: 0.6000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.2616e-05 - accuracy: 1.0000 - val_loss: 3.4386 - val_accuracy: 0.6000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2402e-05 - accuracy: 1.0000 - val_loss: 3.4391 - val_accuracy: 0.6000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2181e-05 - accuracy: 1.0000 - val_loss: 3.4395 - val_accuracy: 0.6000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.1984e-05 - accuracy: 1.0000 - val_loss: 3.4392 - val_accuracy: 0.6000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.1797e-05 - accuracy: 1.0000 - val_loss: 3.4393 - val_accuracy: 0.6000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.1611e-05 - accuracy: 1.0000 - val_loss: 3.4395 - val_accuracy: 0.6000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.1391e-05 - accuracy: 1.0000 - val_loss: 3.4399 - val_accuracy: 0.6000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.1225e-05 - accuracy: 1.0000 - val_loss: 3.4399 - val_accuracy: 0.6000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.1080e-05 - accuracy: 1.0000 - val_loss: 3.4400 - val_accuracy: 0.6000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0908e-05 - accuracy: 1.0000 - val_loss: 3.4397 - val_accuracy: 0.6000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0727e-05 - accuracy: 1.0000 - val_loss: 3.4401 - val_accuracy: 0.6000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0558e-05 - accuracy: 1.0000 - val_loss: 3.4402 - val_accuracy: 0.6000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.0389e-05 - accuracy: 1.0000 - val_loss: 3.4402 - val_accuracy: 0.6000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0250e-05 - accuracy: 1.0000 - val_loss: 3.4404 - val_accuracy: 0.6000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0099e-05 - accuracy: 1.0000 - val_loss: 3.4406 - val_accuracy: 0.6000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 9.9498e-06 - accuracy: 1.0000 - val_loss: 3.4412 - val_accuracy: 0.6000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 9.8261e-06 - accuracy: 1.0000 - val_loss: 3.4412 - val_accuracy: 0.6000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 9.6827e-06 - accuracy: 1.0000 - val_loss: 3.4415 - val_accuracy: 0.6000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 9.5304e-06 - accuracy: 1.0000 - val_loss: 3.4415 - val_accuracy: 0.6000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 9.4157e-06 - accuracy: 1.0000 - val_loss: 3.4414 - val_accuracy: 0.6000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 9.2965e-06 - accuracy: 1.0000 - val_loss: 3.4415 - val_accuracy: 0.6000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9.1667e-06 - accuracy: 1.0000 - val_loss: 3.4420 - val_accuracy: 0.6000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 9.0475e-06 - accuracy: 1.0000 - val_loss: 3.4421 - val_accuracy: 0.6000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.9102e-06 - accuracy: 1.0000 - val_loss: 3.4422 - val_accuracy: 0.6000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.7910e-06 - accuracy: 1.0000 - val_loss: 3.4425 - val_accuracy: 0.6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_four_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 4 Hidden Layer Adam Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_four_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE7-ChDs9l45",
        "outputId": "47df69c1-2e20-4bbe-a7c2-bef6bf785769"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 103ms/step - loss: 3.4425 - accuracy: 0.6000\n",
            "Model 4 Hidden Layer Adam Optimizer Validation Accuracy: 0.6000000238418579\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 11.3297 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('ADAM', 4, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EobxfDdNnXVf",
        "outputId": "98873627-0f7b-4f93-b049-28894074271c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.70           0.76\n",
            "1       SGD             2                 0.70           0.60\n",
            "2       SGD             3                 0.75           0.68\n",
            "3       SGD             4                 0.70           0.52\n",
            "4      ADAM             1                 0.70           0.68\n",
            "5      ADAM             2                 0.65           0.60\n",
            "6      ADAM             3                 0.75           0.60\n",
            "7      ADAM             4                 0.60           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaGrad Optimizer"
      ],
      "metadata": {
        "id": "NEQaPOOJ9ytE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 1 hidden Layer with AdaGrad Optimizer"
      ],
      "metadata": {
        "id": "67AwxiCe91ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_adagrad = tf.keras.optimizers.Adagrad()\n",
        "model_one_hidden_layer.compile(optimizer=optimizer_adagrad, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_one_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-LqJEkx94HA",
        "outputId": "c74a79c7-8689-42b6-fa4a-cc175f177d09"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 133ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 138ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 133ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 140ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 133ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 1s 143ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 142ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 1s 106ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7603 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_one_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 1 Hidden Layer AdaGrad Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_one_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms68QG1M9_dU",
        "outputId": "90f1e851-2e0a-44f2-b2c8-eb6737a6401c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 98ms/step - loss: 20.7603 - accuracy: 0.7000\n",
            "Model 1 Hidden Layer AdaGrad Optimizer Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3.0402 - accuracy: 0.6800\n",
            "Best Model Test Accuracy: 0.6800000071525574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('AdaGrad', 1, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkUF9IEPneAF",
        "outputId": "47efebe3-b096-4af6-d917-5669d73f6bf7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.70           0.76\n",
            "1       SGD             2                 0.70           0.60\n",
            "2       SGD             3                 0.75           0.68\n",
            "3       SGD             4                 0.70           0.52\n",
            "4      ADAM             1                 0.70           0.68\n",
            "5      ADAM             2                 0.65           0.60\n",
            "6      ADAM             3                 0.75           0.60\n",
            "7      ADAM             4                 0.60           0.60\n",
            "8   AdaGrad             1                 0.70           0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 2 hidden Layer with AdaGrad Optimizer"
      ],
      "metadata": {
        "id": "a3MJ-cUrEjq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_adagrad = tf.keras.optimizers.Adagrad()\n",
        "model_two_hidden_layer.compile(optimizer=optimizer_adagrad, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_two_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1QICsdXElpO",
        "outputId": "cee8097d-d0d0-46f5-d562-4082ff6a95aa"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 46ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1903 - val_accuracy: 0.6500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1904 - val_accuracy: 0.6500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1905 - val_accuracy: 0.6500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1906 - val_accuracy: 0.6500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1907 - val_accuracy: 0.6500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1908 - val_accuracy: 0.6500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1908 - val_accuracy: 0.6500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 10.1908 - val_accuracy: 0.6500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_two_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 2 Hidden Layer AdaGrad Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_two_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HFpAJAtEo71",
        "outputId": "927d17a8-52f3-44af-ce4a-22a54820d636"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 409ms/step - loss: 10.1908 - accuracy: 0.6500\n",
            "Model 2 Hidden Layer AdaGrad Optimizer Validation Accuracy: 0.6499999761581421\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 9.1010 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('AdaGrad', 2, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoxOlPqwnmwM",
        "outputId": "b4ff2006-0bef-4e28-a86a-a6932950a14f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0       SGD             1                 0.70           0.76\n",
            "1       SGD             2                 0.70           0.60\n",
            "2       SGD             3                 0.75           0.68\n",
            "3       SGD             4                 0.70           0.52\n",
            "4      ADAM             1                 0.70           0.68\n",
            "5      ADAM             2                 0.65           0.60\n",
            "6      ADAM             3                 0.75           0.60\n",
            "7      ADAM             4                 0.60           0.60\n",
            "8   AdaGrad             1                 0.70           0.68\n",
            "9   AdaGrad             2                 0.65           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 3 hidden Layer with AdaGrad Optimizer"
      ],
      "metadata": {
        "id": "t5kh4TDNFLZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_adagrad = tf.keras.optimizers.Adagrad()\n",
        "model_three_hidden_layer.compile(optimizer=optimizer_adagrad, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_three_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOreTnywFPRl",
        "outputId": "54e66f2e-ff23-4bc5-f183-99142b453a01"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 36ms/step - loss: 7.4845e-07 - accuracy: 1.0000 - val_loss: 2.9431 - val_accuracy: 0.7500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9431 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9431 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9431 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9431 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9431 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9432 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4543e-07 - accuracy: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4543e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4543e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4543e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4543e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4543e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4543e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4543e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4543e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4543e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4543e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9434 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.4241e-07 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_three_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer AdaGrad Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_three_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVlRnqxvFUPv",
        "outputId": "8e662615-b58d-45d3-a4e3-fa1e2257bc86"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 105ms/step - loss: 2.9437 - accuracy: 0.7500\n",
            "Model 3 Hidden Layer AdaGrad Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 19.9436 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('AdaGrad', 3, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmGdQnSCntPJ",
        "outputId": "cafc441c-b8a9-452a-f3bc-47afcb16cb3e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.70           0.76\n",
            "1        SGD             2                 0.70           0.60\n",
            "2        SGD             3                 0.75           0.68\n",
            "3        SGD             4                 0.70           0.52\n",
            "4       ADAM             1                 0.70           0.68\n",
            "5       ADAM             2                 0.65           0.60\n",
            "6       ADAM             3                 0.75           0.60\n",
            "7       ADAM             4                 0.60           0.60\n",
            "8    AdaGrad             1                 0.70           0.68\n",
            "9    AdaGrad             2                 0.65           0.60\n",
            "10   AdaGrad             3                 0.75           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 4 hidden Layer with AdaGrad Optimizer"
      ],
      "metadata": {
        "id": "GoRcbSIJGIVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_adagrad = tf.keras.optimizers.Adagrad()\n",
        "model_four_hidden_layer.compile(optimizer=optimizer_adagrad, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_four_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVjrrQwvGKNn",
        "outputId": "dfbd6e8b-46ca-46db-dd1e-135e2745d853"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 28ms/step - loss: 8.7231e-06 - accuracy: 1.0000 - val_loss: 3.4425 - val_accuracy: 0.6000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.7216e-06 - accuracy: 1.0000 - val_loss: 3.4425 - val_accuracy: 0.6000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 8.7186e-06 - accuracy: 1.0000 - val_loss: 3.4425 - val_accuracy: 0.6000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.7171e-06 - accuracy: 1.0000 - val_loss: 3.4425 - val_accuracy: 0.6000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.7125e-06 - accuracy: 1.0000 - val_loss: 3.4425 - val_accuracy: 0.6000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 8.7095e-06 - accuracy: 1.0000 - val_loss: 3.4425 - val_accuracy: 0.6000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 8.7095e-06 - accuracy: 1.0000 - val_loss: 3.4425 - val_accuracy: 0.6000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 8.7080e-06 - accuracy: 1.0000 - val_loss: 3.4425 - val_accuracy: 0.6000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.7065e-06 - accuracy: 1.0000 - val_loss: 3.4426 - val_accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 8.7050e-06 - accuracy: 1.0000 - val_loss: 3.4426 - val_accuracy: 0.6000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.7035e-06 - accuracy: 1.0000 - val_loss: 3.4426 - val_accuracy: 0.6000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.7005e-06 - accuracy: 1.0000 - val_loss: 3.4426 - val_accuracy: 0.6000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.6975e-06 - accuracy: 1.0000 - val_loss: 3.4426 - val_accuracy: 0.6000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 8.6944e-06 - accuracy: 1.0000 - val_loss: 3.4426 - val_accuracy: 0.6000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 8.6929e-06 - accuracy: 1.0000 - val_loss: 3.4426 - val_accuracy: 0.6000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.6929e-06 - accuracy: 1.0000 - val_loss: 3.4426 - val_accuracy: 0.6000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6899e-06 - accuracy: 1.0000 - val_loss: 3.4427 - val_accuracy: 0.6000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 8.6899e-06 - accuracy: 1.0000 - val_loss: 3.4427 - val_accuracy: 0.6000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6869e-06 - accuracy: 1.0000 - val_loss: 3.4427 - val_accuracy: 0.6000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6839e-06 - accuracy: 1.0000 - val_loss: 3.4427 - val_accuracy: 0.6000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6824e-06 - accuracy: 1.0000 - val_loss: 3.4427 - val_accuracy: 0.6000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 8.6824e-06 - accuracy: 1.0000 - val_loss: 3.4427 - val_accuracy: 0.6000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6809e-06 - accuracy: 1.0000 - val_loss: 3.4427 - val_accuracy: 0.6000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6793e-06 - accuracy: 1.0000 - val_loss: 3.4427 - val_accuracy: 0.6000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6763e-06 - accuracy: 1.0000 - val_loss: 3.4428 - val_accuracy: 0.6000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6718e-06 - accuracy: 1.0000 - val_loss: 3.4428 - val_accuracy: 0.6000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.6703e-06 - accuracy: 1.0000 - val_loss: 3.4428 - val_accuracy: 0.6000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6688e-06 - accuracy: 1.0000 - val_loss: 3.4428 - val_accuracy: 0.6000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6688e-06 - accuracy: 1.0000 - val_loss: 3.4428 - val_accuracy: 0.6000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.6688e-06 - accuracy: 1.0000 - val_loss: 3.4428 - val_accuracy: 0.6000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6658e-06 - accuracy: 1.0000 - val_loss: 3.4428 - val_accuracy: 0.6000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6628e-06 - accuracy: 1.0000 - val_loss: 3.4428 - val_accuracy: 0.6000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6612e-06 - accuracy: 1.0000 - val_loss: 3.4429 - val_accuracy: 0.6000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6597e-06 - accuracy: 1.0000 - val_loss: 3.4429 - val_accuracy: 0.6000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6597e-06 - accuracy: 1.0000 - val_loss: 3.4429 - val_accuracy: 0.6000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6567e-06 - accuracy: 1.0000 - val_loss: 3.4429 - val_accuracy: 0.6000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6507e-06 - accuracy: 1.0000 - val_loss: 3.4429 - val_accuracy: 0.6000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6507e-06 - accuracy: 1.0000 - val_loss: 3.4429 - val_accuracy: 0.6000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 8.6507e-06 - accuracy: 1.0000 - val_loss: 3.4429 - val_accuracy: 0.6000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6477e-06 - accuracy: 1.0000 - val_loss: 3.4429 - val_accuracy: 0.6000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.6462e-06 - accuracy: 1.0000 - val_loss: 3.4429 - val_accuracy: 0.6000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.6462e-06 - accuracy: 1.0000 - val_loss: 3.4430 - val_accuracy: 0.6000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.6416e-06 - accuracy: 1.0000 - val_loss: 3.4430 - val_accuracy: 0.6000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6416e-06 - accuracy: 1.0000 - val_loss: 3.4430 - val_accuracy: 0.6000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6416e-06 - accuracy: 1.0000 - val_loss: 3.4430 - val_accuracy: 0.6000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6386e-06 - accuracy: 1.0000 - val_loss: 3.4430 - val_accuracy: 0.6000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6341e-06 - accuracy: 1.0000 - val_loss: 3.4430 - val_accuracy: 0.6000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6311e-06 - accuracy: 1.0000 - val_loss: 3.4430 - val_accuracy: 0.6000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6280e-06 - accuracy: 1.0000 - val_loss: 3.4430 - val_accuracy: 0.6000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.6265e-06 - accuracy: 1.0000 - val_loss: 3.4431 - val_accuracy: 0.6000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.6265e-06 - accuracy: 1.0000 - val_loss: 3.4431 - val_accuracy: 0.6000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.6250e-06 - accuracy: 1.0000 - val_loss: 3.4431 - val_accuracy: 0.6000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.6235e-06 - accuracy: 1.0000 - val_loss: 3.4431 - val_accuracy: 0.6000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.6220e-06 - accuracy: 1.0000 - val_loss: 3.4431 - val_accuracy: 0.6000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6175e-06 - accuracy: 1.0000 - val_loss: 3.4431 - val_accuracy: 0.6000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6145e-06 - accuracy: 1.0000 - val_loss: 3.4431 - val_accuracy: 0.6000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6130e-06 - accuracy: 1.0000 - val_loss: 3.4431 - val_accuracy: 0.6000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6130e-06 - accuracy: 1.0000 - val_loss: 3.4432 - val_accuracy: 0.6000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6099e-06 - accuracy: 1.0000 - val_loss: 3.4432 - val_accuracy: 0.6000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6084e-06 - accuracy: 1.0000 - val_loss: 3.4432 - val_accuracy: 0.6000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6084e-06 - accuracy: 1.0000 - val_loss: 3.4432 - val_accuracy: 0.6000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.6069e-06 - accuracy: 1.0000 - val_loss: 3.4432 - val_accuracy: 0.6000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6024e-06 - accuracy: 1.0000 - val_loss: 3.4432 - val_accuracy: 0.6000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6024e-06 - accuracy: 1.0000 - val_loss: 3.4432 - val_accuracy: 0.6000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.6009e-06 - accuracy: 1.0000 - val_loss: 3.4432 - val_accuracy: 0.6000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 8.6009e-06 - accuracy: 1.0000 - val_loss: 3.4432 - val_accuracy: 0.6000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5979e-06 - accuracy: 1.0000 - val_loss: 3.4433 - val_accuracy: 0.6000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5949e-06 - accuracy: 1.0000 - val_loss: 3.4433 - val_accuracy: 0.6000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.5918e-06 - accuracy: 1.0000 - val_loss: 3.4433 - val_accuracy: 0.6000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5903e-06 - accuracy: 1.0000 - val_loss: 3.4433 - val_accuracy: 0.6000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5873e-06 - accuracy: 1.0000 - val_loss: 3.4433 - val_accuracy: 0.6000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5873e-06 - accuracy: 1.0000 - val_loss: 3.4433 - val_accuracy: 0.6000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5858e-06 - accuracy: 1.0000 - val_loss: 3.4433 - val_accuracy: 0.6000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.5858e-06 - accuracy: 1.0000 - val_loss: 3.4433 - val_accuracy: 0.6000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5828e-06 - accuracy: 1.0000 - val_loss: 3.4434 - val_accuracy: 0.6000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5813e-06 - accuracy: 1.0000 - val_loss: 3.4434 - val_accuracy: 0.6000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 8.5783e-06 - accuracy: 1.0000 - val_loss: 3.4434 - val_accuracy: 0.6000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5737e-06 - accuracy: 1.0000 - val_loss: 3.4434 - val_accuracy: 0.6000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5737e-06 - accuracy: 1.0000 - val_loss: 3.4434 - val_accuracy: 0.6000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5737e-06 - accuracy: 1.0000 - val_loss: 3.4434 - val_accuracy: 0.6000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5707e-06 - accuracy: 1.0000 - val_loss: 3.4434 - val_accuracy: 0.6000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5707e-06 - accuracy: 1.0000 - val_loss: 3.4434 - val_accuracy: 0.6000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5692e-06 - accuracy: 1.0000 - val_loss: 3.4435 - val_accuracy: 0.6000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.5677e-06 - accuracy: 1.0000 - val_loss: 3.4435 - val_accuracy: 0.6000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5647e-06 - accuracy: 1.0000 - val_loss: 3.4435 - val_accuracy: 0.6000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5647e-06 - accuracy: 1.0000 - val_loss: 3.4435 - val_accuracy: 0.6000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5632e-06 - accuracy: 1.0000 - val_loss: 3.4435 - val_accuracy: 0.6000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5556e-06 - accuracy: 1.0000 - val_loss: 3.4435 - val_accuracy: 0.6000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5556e-06 - accuracy: 1.0000 - val_loss: 3.4435 - val_accuracy: 0.6000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5511e-06 - accuracy: 1.0000 - val_loss: 3.4435 - val_accuracy: 0.6000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5511e-06 - accuracy: 1.0000 - val_loss: 3.4436 - val_accuracy: 0.6000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5496e-06 - accuracy: 1.0000 - val_loss: 3.4436 - val_accuracy: 0.6000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5466e-06 - accuracy: 1.0000 - val_loss: 3.4436 - val_accuracy: 0.6000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5436e-06 - accuracy: 1.0000 - val_loss: 3.4436 - val_accuracy: 0.6000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.5436e-06 - accuracy: 1.0000 - val_loss: 3.4436 - val_accuracy: 0.6000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.5420e-06 - accuracy: 1.0000 - val_loss: 3.4436 - val_accuracy: 0.6000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 8.5420e-06 - accuracy: 1.0000 - val_loss: 3.4436 - val_accuracy: 0.6000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.5405e-06 - accuracy: 1.0000 - val_loss: 3.4436 - val_accuracy: 0.6000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5375e-06 - accuracy: 1.0000 - val_loss: 3.4437 - val_accuracy: 0.6000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 8.5360e-06 - accuracy: 1.0000 - val_loss: 3.4437 - val_accuracy: 0.6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_four_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 4 Hidden Layer AdaGrad Optimizer Validation Accuracy:\", val_acc)\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_four_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZAGCiBqGPYi",
        "outputId": "e707d901-d46b-4f75-8007-fc6841cb374f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 106ms/step - loss: 3.4437 - accuracy: 0.6000\n",
            "Model 4 Hidden Layer AdaGrad Optimizer Validation Accuracy: 0.6000000238418579\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 11.3314 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('AdaGrad', 4, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCkaPv9vn096",
        "outputId": "bc0d1b7c-3d1b-44b0-8640-89c46300b737"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.70           0.76\n",
            "1        SGD             2                 0.70           0.60\n",
            "2        SGD             3                 0.75           0.68\n",
            "3        SGD             4                 0.70           0.52\n",
            "4       ADAM             1                 0.70           0.68\n",
            "5       ADAM             2                 0.65           0.60\n",
            "6       ADAM             3                 0.75           0.60\n",
            "7       ADAM             4                 0.60           0.60\n",
            "8    AdaGrad             1                 0.70           0.68\n",
            "9    AdaGrad             2                 0.65           0.60\n",
            "10   AdaGrad             3                 0.75           0.60\n",
            "11   AdaGrad             4                 0.60           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSProp Optimizer"
      ],
      "metadata": {
        "id": "iaxEXMazGclz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 1 hidden Layer with RMSProp Optimizer"
      ],
      "metadata": {
        "id": "MbPhC4dQGexU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_rmsprop = tf.keras.optimizers.RMSprop()\n",
        "model_one_hidden_layer.compile(optimizer=optimizer_rmsprop, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_one_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCoyReb8GhHa",
        "outputId": "a68b69c6-7cc7-4129-abd9-c242aee77e1b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 111ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7604 - val_accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7605 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 1.5090e-08 - accuracy: 1.0000 - val_loss: 20.7606 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 133ms/step - loss: 1.3581e-08 - accuracy: 1.0000 - val_loss: 20.7607 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 127ms/step - loss: 1.3581e-08 - accuracy: 1.0000 - val_loss: 20.7608 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 1.3581e-08 - accuracy: 1.0000 - val_loss: 20.7609 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 1.3581e-08 - accuracy: 1.0000 - val_loss: 20.7610 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 1.3581e-08 - accuracy: 1.0000 - val_loss: 20.7611 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 20.7612 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 1.2072e-08 - accuracy: 1.0000 - val_loss: 20.7613 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 20.7614 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 20.7615 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 20.7616 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 20.7617 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 20.7618 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 20.7619 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 1s 141ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 20.7620 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 20.7621 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 20.7622 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 20.7623 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 1.0563e-08 - accuracy: 1.0000 - val_loss: 20.7624 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7625 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7626 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7627 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7628 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7629 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7630 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7631 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7632 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7634 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 1s 140ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7635 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7636 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7637 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7638 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7639 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7640 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7641 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7642 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7644 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 9.0539e-09 - accuracy: 1.0000 - val_loss: 20.7645 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7646 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7647 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7648 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7649 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 130ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7650 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 1s 131ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7652 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7653 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7654 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7655 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7656 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7657 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7658 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7659 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 1s 102ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7661 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7662 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7663 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7664 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7665 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 1s 138ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7667 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 125ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7668 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7669 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7670 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7671 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 1s 102ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7672 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7674 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7675 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7676 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7677 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7678 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7679 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 7.5449e-09 - accuracy: 1.0000 - val_loss: 20.7681 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7682 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 137ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7683 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 127ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7684 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7685 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7686 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7687 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7689 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7690 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7691 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7692 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7693 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7694 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7696 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7697 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7698 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7699 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7700 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7701 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7703 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7704 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7705 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7706 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7707 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7708 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7709 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7711 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7712 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 6.0359e-09 - accuracy: 1.0000 - val_loss: 20.7713 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_one_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 1 Hidden Layer RMSprop Optimizer Validation Accuracy:\", val_acc)\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_one_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4wqk_7HGmZd",
        "outputId": "dab1fbcb-5366-487f-8eaf-0715fee3902e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step - loss: 20.7713 - accuracy: 0.7000\n",
            "Model 1 Hidden Layer RMSprop Optimizer Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 3.2224 - accuracy: 0.6400\n",
            "Best Model Test Accuracy: 0.6399999856948853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('RMSprop', 1, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kImMzSmtn8yc",
        "outputId": "3c932d95-c28c-4e0b-f10d-a71078137894"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.70           0.76\n",
            "1        SGD             2                 0.70           0.60\n",
            "2        SGD             3                 0.75           0.68\n",
            "3        SGD             4                 0.70           0.52\n",
            "4       ADAM             1                 0.70           0.68\n",
            "5       ADAM             2                 0.65           0.60\n",
            "6       ADAM             3                 0.75           0.60\n",
            "7       ADAM             4                 0.60           0.60\n",
            "8    AdaGrad             1                 0.70           0.68\n",
            "9    AdaGrad             2                 0.65           0.60\n",
            "10   AdaGrad             3                 0.75           0.60\n",
            "11   AdaGrad             4                 0.60           0.60\n",
            "12   RMSprop             1                 0.70           0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 2 hidden Layer with RMSProp Optimizer"
      ],
      "metadata": {
        "id": "HEBF89FnHdNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_rmsprop = tf.keras.optimizers.RMSprop()\n",
        "model_two_hidden_layer.compile(optimizer=optimizer_rmsprop, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_two_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vigEQ8CHe7v",
        "outputId": "94231d04-ced5-49ac-ebd7-2b35a7c57246"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 55ms/step - loss: 4.4062e-07 - accuracy: 1.0000 - val_loss: 10.1960 - val_accuracy: 0.6500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 4.1044e-07 - accuracy: 1.0000 - val_loss: 10.2011 - val_accuracy: 0.6500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 3.8177e-07 - accuracy: 1.0000 - val_loss: 10.2057 - val_accuracy: 0.6500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.5762e-07 - accuracy: 1.0000 - val_loss: 10.2098 - val_accuracy: 0.6500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 3.3650e-07 - accuracy: 1.0000 - val_loss: 10.2137 - val_accuracy: 0.6500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 3.1990e-07 - accuracy: 1.0000 - val_loss: 10.2175 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 3.0179e-07 - accuracy: 1.0000 - val_loss: 10.2209 - val_accuracy: 0.6500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.8821e-07 - accuracy: 1.0000 - val_loss: 10.2241 - val_accuracy: 0.6500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 2.7463e-07 - accuracy: 1.0000 - val_loss: 10.2272 - val_accuracy: 0.6500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 2.6105e-07 - accuracy: 1.0000 - val_loss: 10.2300 - val_accuracy: 0.6500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.5200e-07 - accuracy: 1.0000 - val_loss: 10.2327 - val_accuracy: 0.6500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.4144e-07 - accuracy: 1.0000 - val_loss: 10.2354 - val_accuracy: 0.6500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 2.3238e-07 - accuracy: 1.0000 - val_loss: 10.2378 - val_accuracy: 0.6500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 2.2333e-07 - accuracy: 1.0000 - val_loss: 10.2402 - val_accuracy: 0.6500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 2.1729e-07 - accuracy: 1.0000 - val_loss: 10.2425 - val_accuracy: 0.6500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.0824e-07 - accuracy: 1.0000 - val_loss: 10.2447 - val_accuracy: 0.6500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 2.0220e-07 - accuracy: 1.0000 - val_loss: 10.2473 - val_accuracy: 0.6500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.9617e-07 - accuracy: 1.0000 - val_loss: 10.2493 - val_accuracy: 0.6500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.9013e-07 - accuracy: 1.0000 - val_loss: 10.2513 - val_accuracy: 0.6500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 1.8259e-07 - accuracy: 1.0000 - val_loss: 10.2531 - val_accuracy: 0.6500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.7806e-07 - accuracy: 1.0000 - val_loss: 10.2549 - val_accuracy: 0.6500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.7353e-07 - accuracy: 1.0000 - val_loss: 10.2567 - val_accuracy: 0.6500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.6900e-07 - accuracy: 1.0000 - val_loss: 10.2585 - val_accuracy: 0.6500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.6448e-07 - accuracy: 1.0000 - val_loss: 10.2601 - val_accuracy: 0.6500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.5844e-07 - accuracy: 1.0000 - val_loss: 10.2618 - val_accuracy: 0.6500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.5392e-07 - accuracy: 1.0000 - val_loss: 10.2634 - val_accuracy: 0.6500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.4939e-07 - accuracy: 1.0000 - val_loss: 10.2650 - val_accuracy: 0.6500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.4788e-07 - accuracy: 1.0000 - val_loss: 10.2665 - val_accuracy: 0.6500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.4335e-07 - accuracy: 1.0000 - val_loss: 10.2680 - val_accuracy: 0.6500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.4184e-07 - accuracy: 1.0000 - val_loss: 10.2697 - val_accuracy: 0.6500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3732e-07 - accuracy: 1.0000 - val_loss: 10.2711 - val_accuracy: 0.6500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.3581e-07 - accuracy: 1.0000 - val_loss: 10.2726 - val_accuracy: 0.6500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.3128e-07 - accuracy: 1.0000 - val_loss: 10.2739 - val_accuracy: 0.6500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.2826e-07 - accuracy: 1.0000 - val_loss: 10.2753 - val_accuracy: 0.6500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.2524e-07 - accuracy: 1.0000 - val_loss: 10.2765 - val_accuracy: 0.6500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.2223e-07 - accuracy: 1.0000 - val_loss: 10.2778 - val_accuracy: 0.6500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.2072e-07 - accuracy: 1.0000 - val_loss: 10.2790 - val_accuracy: 0.6500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.1770e-07 - accuracy: 1.0000 - val_loss: 10.2802 - val_accuracy: 0.6500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1619e-07 - accuracy: 1.0000 - val_loss: 10.2814 - val_accuracy: 0.6500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1317e-07 - accuracy: 1.0000 - val_loss: 10.2825 - val_accuracy: 0.6500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.1166e-07 - accuracy: 1.0000 - val_loss: 10.2837 - val_accuracy: 0.6500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.1016e-07 - accuracy: 1.0000 - val_loss: 10.2850 - val_accuracy: 0.6500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.0714e-07 - accuracy: 1.0000 - val_loss: 10.2861 - val_accuracy: 0.6500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.0563e-07 - accuracy: 1.0000 - val_loss: 10.2871 - val_accuracy: 0.6500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.0412e-07 - accuracy: 1.0000 - val_loss: 10.2882 - val_accuracy: 0.6500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.0261e-07 - accuracy: 1.0000 - val_loss: 10.2892 - val_accuracy: 0.6500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.0110e-07 - accuracy: 1.0000 - val_loss: 10.2903 - val_accuracy: 0.6500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 9.9592e-08 - accuracy: 1.0000 - val_loss: 10.2915 - val_accuracy: 0.6500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 9.8083e-08 - accuracy: 1.0000 - val_loss: 10.2925 - val_accuracy: 0.6500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 9.5065e-08 - accuracy: 1.0000 - val_loss: 10.2935 - val_accuracy: 0.6500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 9.5065e-08 - accuracy: 1.0000 - val_loss: 10.2943 - val_accuracy: 0.6500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 9.3556e-08 - accuracy: 1.0000 - val_loss: 10.2953 - val_accuracy: 0.6500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 9.2047e-08 - accuracy: 1.0000 - val_loss: 10.2962 - val_accuracy: 0.6500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 9.0539e-08 - accuracy: 1.0000 - val_loss: 10.2970 - val_accuracy: 0.6500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 8.9030e-08 - accuracy: 1.0000 - val_loss: 10.2979 - val_accuracy: 0.6500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 8.7521e-08 - accuracy: 1.0000 - val_loss: 10.2988 - val_accuracy: 0.6500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 8.7521e-08 - accuracy: 1.0000 - val_loss: 10.2996 - val_accuracy: 0.6500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 8.6012e-08 - accuracy: 1.0000 - val_loss: 10.3005 - val_accuracy: 0.6500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 8.4503e-08 - accuracy: 1.0000 - val_loss: 10.3014 - val_accuracy: 0.6500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 8.2994e-08 - accuracy: 1.0000 - val_loss: 10.3022 - val_accuracy: 0.6500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 10.3030 - val_accuracy: 0.6500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 8.1485e-08 - accuracy: 1.0000 - val_loss: 10.3038 - val_accuracy: 0.6500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 7.9976e-08 - accuracy: 1.0000 - val_loss: 10.3048 - val_accuracy: 0.6500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 7.8467e-08 - accuracy: 1.0000 - val_loss: 10.3055 - val_accuracy: 0.6500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 7.6958e-08 - accuracy: 1.0000 - val_loss: 10.3062 - val_accuracy: 0.6500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 7.6958e-08 - accuracy: 1.0000 - val_loss: 10.3069 - val_accuracy: 0.6500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 7.6958e-08 - accuracy: 1.0000 - val_loss: 10.3077 - val_accuracy: 0.6500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 7.5449e-08 - accuracy: 1.0000 - val_loss: 10.3084 - val_accuracy: 0.6500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 7.5449e-08 - accuracy: 1.0000 - val_loss: 10.3091 - val_accuracy: 0.6500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 7.3940e-08 - accuracy: 1.0000 - val_loss: 10.3098 - val_accuracy: 0.6500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 7.2431e-08 - accuracy: 1.0000 - val_loss: 10.3105 - val_accuracy: 0.6500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 7.0922e-08 - accuracy: 1.0000 - val_loss: 10.3113 - val_accuracy: 0.6500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 7.0922e-08 - accuracy: 1.0000 - val_loss: 10.3121 - val_accuracy: 0.6500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 7.0922e-08 - accuracy: 1.0000 - val_loss: 10.3127 - val_accuracy: 0.6500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 6.9413e-08 - accuracy: 1.0000 - val_loss: 10.3134 - val_accuracy: 0.6500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 6.9413e-08 - accuracy: 1.0000 - val_loss: 10.3142 - val_accuracy: 0.6500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 6.9413e-08 - accuracy: 1.0000 - val_loss: 10.3148 - val_accuracy: 0.6500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 6.7904e-08 - accuracy: 1.0000 - val_loss: 10.3154 - val_accuracy: 0.6500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 6.6395e-08 - accuracy: 1.0000 - val_loss: 10.3160 - val_accuracy: 0.6500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 6.4886e-08 - accuracy: 1.0000 - val_loss: 10.3166 - val_accuracy: 0.6500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 6.4886e-08 - accuracy: 1.0000 - val_loss: 10.3172 - val_accuracy: 0.6500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 6.4886e-08 - accuracy: 1.0000 - val_loss: 10.3179 - val_accuracy: 0.6500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 6.3377e-08 - accuracy: 1.0000 - val_loss: 10.3185 - val_accuracy: 0.6500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 6.3377e-08 - accuracy: 1.0000 - val_loss: 10.3191 - val_accuracy: 0.6500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 6.3377e-08 - accuracy: 1.0000 - val_loss: 10.3198 - val_accuracy: 0.6500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 6.3377e-08 - accuracy: 1.0000 - val_loss: 10.3204 - val_accuracy: 0.6500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 6.1868e-08 - accuracy: 1.0000 - val_loss: 10.3211 - val_accuracy: 0.6500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 6.1868e-08 - accuracy: 1.0000 - val_loss: 10.3217 - val_accuracy: 0.6500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 6.0359e-08 - accuracy: 1.0000 - val_loss: 10.3222 - val_accuracy: 0.6500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 6.0359e-08 - accuracy: 1.0000 - val_loss: 10.3228 - val_accuracy: 0.6500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 5.8850e-08 - accuracy: 1.0000 - val_loss: 10.3233 - val_accuracy: 0.6500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 5.8850e-08 - accuracy: 1.0000 - val_loss: 10.3239 - val_accuracy: 0.6500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 5.8850e-08 - accuracy: 1.0000 - val_loss: 10.3246 - val_accuracy: 0.6500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 5.7341e-08 - accuracy: 1.0000 - val_loss: 10.3251 - val_accuracy: 0.6500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 5.7341e-08 - accuracy: 1.0000 - val_loss: 10.3257 - val_accuracy: 0.6500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 5.7341e-08 - accuracy: 1.0000 - val_loss: 10.3262 - val_accuracy: 0.6500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 5.7341e-08 - accuracy: 1.0000 - val_loss: 10.3267 - val_accuracy: 0.6500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 5.5832e-08 - accuracy: 1.0000 - val_loss: 10.3272 - val_accuracy: 0.6500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 5.5832e-08 - accuracy: 1.0000 - val_loss: 10.3278 - val_accuracy: 0.6500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 5.5832e-08 - accuracy: 1.0000 - val_loss: 10.3283 - val_accuracy: 0.6500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_two_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 2 Hidden Layer RMSprop Optimizer Validation Accuracy:\", val_acc)\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_two_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkhmAHRpHiDY",
        "outputId": "0ea4d80a-671d-4814-bbc2-e18552ef874f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 98ms/step - loss: 10.3283 - accuracy: 0.6500\n",
            "Model 2 Hidden Layer RMSprop Optimizer Validation Accuracy: 0.6499999761581421\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 9.5729 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('RMSprop', 2, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cMYcBbyoIlv",
        "outputId": "0dee08e3-8035-4170-c9e0-ccbe6da086b5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.70           0.76\n",
            "1        SGD             2                 0.70           0.60\n",
            "2        SGD             3                 0.75           0.68\n",
            "3        SGD             4                 0.70           0.52\n",
            "4       ADAM             1                 0.70           0.68\n",
            "5       ADAM             2                 0.65           0.60\n",
            "6       ADAM             3                 0.75           0.60\n",
            "7       ADAM             4                 0.60           0.60\n",
            "8    AdaGrad             1                 0.70           0.68\n",
            "9    AdaGrad             2                 0.65           0.60\n",
            "10   AdaGrad             3                 0.75           0.60\n",
            "11   AdaGrad             4                 0.60           0.60\n",
            "12   RMSprop             1                 0.70           0.64\n",
            "13   RMSprop             2                 0.65           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 3 hidden Layer with RMSProp Optimizer"
      ],
      "metadata": {
        "id": "6JTe98PXHsgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_rmsprop = tf.keras.optimizers.RMSprop()\n",
        "model_three_hidden_layer.compile(optimizer=optimizer_rmsprop, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_three_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoZ8zb9BHuiZ",
        "outputId": "f543c825-b762-4973-d510-2f0dfc83fe67"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 37ms/step - loss: 7.4392e-07 - accuracy: 1.0000 - val_loss: 2.9510 - val_accuracy: 0.7500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 6.7904e-07 - accuracy: 1.0000 - val_loss: 2.9573 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 6.2924e-07 - accuracy: 1.0000 - val_loss: 2.9633 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 5.9303e-07 - accuracy: 1.0000 - val_loss: 2.9687 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 5.5379e-07 - accuracy: 1.0000 - val_loss: 2.9736 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 5.2663e-07 - accuracy: 1.0000 - val_loss: 2.9783 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 5.0551e-07 - accuracy: 1.0000 - val_loss: 2.9827 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 4.7834e-07 - accuracy: 1.0000 - val_loss: 2.9869 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 4.5873e-07 - accuracy: 1.0000 - val_loss: 2.9908 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 2.9946 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4.2402e-07 - accuracy: 1.0000 - val_loss: 2.9981 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 4.1044e-07 - accuracy: 1.0000 - val_loss: 3.0015 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.9384e-07 - accuracy: 1.0000 - val_loss: 3.0048 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 3.8177e-07 - accuracy: 1.0000 - val_loss: 3.0079 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.6970e-07 - accuracy: 1.0000 - val_loss: 3.0110 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.5914e-07 - accuracy: 1.0000 - val_loss: 3.0139 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 3.5008e-07 - accuracy: 1.0000 - val_loss: 3.0167 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.3952e-07 - accuracy: 1.0000 - val_loss: 3.0194 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.3197e-07 - accuracy: 1.0000 - val_loss: 3.0221 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.1990e-07 - accuracy: 1.0000 - val_loss: 3.0247 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 3.1236e-07 - accuracy: 1.0000 - val_loss: 3.0273 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.0783e-07 - accuracy: 1.0000 - val_loss: 3.0298 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 2.9878e-07 - accuracy: 1.0000 - val_loss: 3.0323 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.9425e-07 - accuracy: 1.0000 - val_loss: 3.0346 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.8821e-07 - accuracy: 1.0000 - val_loss: 3.0370 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.8218e-07 - accuracy: 1.0000 - val_loss: 3.0393 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.7463e-07 - accuracy: 1.0000 - val_loss: 3.0415 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.6860e-07 - accuracy: 1.0000 - val_loss: 3.0436 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.6407e-07 - accuracy: 1.0000 - val_loss: 3.0457 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.5954e-07 - accuracy: 1.0000 - val_loss: 3.0477 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.5653e-07 - accuracy: 1.0000 - val_loss: 3.0498 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.5200e-07 - accuracy: 1.0000 - val_loss: 3.0517 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.4596e-07 - accuracy: 1.0000 - val_loss: 3.0537 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.4295e-07 - accuracy: 1.0000 - val_loss: 3.0557 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.3540e-07 - accuracy: 1.0000 - val_loss: 3.0575 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.3389e-07 - accuracy: 1.0000 - val_loss: 3.0594 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.2635e-07 - accuracy: 1.0000 - val_loss: 3.0612 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.2333e-07 - accuracy: 1.0000 - val_loss: 3.0630 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.2031e-07 - accuracy: 1.0000 - val_loss: 3.0647 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.1729e-07 - accuracy: 1.0000 - val_loss: 3.0664 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.1729e-07 - accuracy: 1.0000 - val_loss: 3.0681 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.1126e-07 - accuracy: 1.0000 - val_loss: 3.0698 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.0824e-07 - accuracy: 1.0000 - val_loss: 3.0714 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.0824e-07 - accuracy: 1.0000 - val_loss: 3.0731 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.0522e-07 - accuracy: 1.0000 - val_loss: 3.0747 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.0069e-07 - accuracy: 1.0000 - val_loss: 3.0763 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.9617e-07 - accuracy: 1.0000 - val_loss: 3.0778 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 1.9315e-07 - accuracy: 1.0000 - val_loss: 3.0794 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.9013e-07 - accuracy: 1.0000 - val_loss: 3.0809 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.8862e-07 - accuracy: 1.0000 - val_loss: 3.0824 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.8711e-07 - accuracy: 1.0000 - val_loss: 3.0838 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.8711e-07 - accuracy: 1.0000 - val_loss: 3.0853 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.8410e-07 - accuracy: 1.0000 - val_loss: 3.0868 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.8108e-07 - accuracy: 1.0000 - val_loss: 3.0882 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.7655e-07 - accuracy: 1.0000 - val_loss: 3.0896 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.7353e-07 - accuracy: 1.0000 - val_loss: 3.0909 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.7353e-07 - accuracy: 1.0000 - val_loss: 3.0922 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.7353e-07 - accuracy: 1.0000 - val_loss: 3.0936 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.7202e-07 - accuracy: 1.0000 - val_loss: 3.0949 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 1.7051e-07 - accuracy: 1.0000 - val_loss: 3.0962 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 1.6750e-07 - accuracy: 1.0000 - val_loss: 3.0976 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1.6448e-07 - accuracy: 1.0000 - val_loss: 3.0989 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.5995e-07 - accuracy: 1.0000 - val_loss: 3.1001 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.5844e-07 - accuracy: 1.0000 - val_loss: 3.1013 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1.5844e-07 - accuracy: 1.0000 - val_loss: 3.1026 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.5392e-07 - accuracy: 1.0000 - val_loss: 3.1038 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.5241e-07 - accuracy: 1.0000 - val_loss: 3.1050 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5241e-07 - accuracy: 1.0000 - val_loss: 3.1062 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.5241e-07 - accuracy: 1.0000 - val_loss: 3.1074 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5090e-07 - accuracy: 1.0000 - val_loss: 3.1086 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1.4788e-07 - accuracy: 1.0000 - val_loss: 3.1097 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4637e-07 - accuracy: 1.0000 - val_loss: 3.1109 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.4486e-07 - accuracy: 1.0000 - val_loss: 3.1120 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.4033e-07 - accuracy: 1.0000 - val_loss: 3.1131 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.4184e-07 - accuracy: 1.0000 - val_loss: 3.1142 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.4184e-07 - accuracy: 1.0000 - val_loss: 3.1153 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4033e-07 - accuracy: 1.0000 - val_loss: 3.1163 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.3732e-07 - accuracy: 1.0000 - val_loss: 3.1174 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.3883e-07 - accuracy: 1.0000 - val_loss: 3.1185 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.3732e-07 - accuracy: 1.0000 - val_loss: 3.1195 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.3732e-07 - accuracy: 1.0000 - val_loss: 3.1206 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.3430e-07 - accuracy: 1.0000 - val_loss: 3.1216 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.3279e-07 - accuracy: 1.0000 - val_loss: 3.1226 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.2977e-07 - accuracy: 1.0000 - val_loss: 3.1236 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.2977e-07 - accuracy: 1.0000 - val_loss: 3.1246 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.2826e-07 - accuracy: 1.0000 - val_loss: 3.1256 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.2374e-07 - accuracy: 1.0000 - val_loss: 3.1266 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.2223e-07 - accuracy: 1.0000 - val_loss: 3.1275 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.2223e-07 - accuracy: 1.0000 - val_loss: 3.1285 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.2223e-07 - accuracy: 1.0000 - val_loss: 3.1294 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.2223e-07 - accuracy: 1.0000 - val_loss: 3.1303 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.2072e-07 - accuracy: 1.0000 - val_loss: 3.1313 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2072e-07 - accuracy: 1.0000 - val_loss: 3.1322 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.2072e-07 - accuracy: 1.0000 - val_loss: 3.1331 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.1770e-07 - accuracy: 1.0000 - val_loss: 3.1340 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.1619e-07 - accuracy: 1.0000 - val_loss: 3.1349 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1468e-07 - accuracy: 1.0000 - val_loss: 3.1358 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1317e-07 - accuracy: 1.0000 - val_loss: 3.1367 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.1317e-07 - accuracy: 1.0000 - val_loss: 3.1375 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1.1317e-07 - accuracy: 1.0000 - val_loss: 3.1384 - val_accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_three_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer RMSprop Optimizer Validation Accuracy:\", val_acc)\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_three_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDmK-HTEHu9f",
        "outputId": "5554191b-d175-41fb-82ce-5ea460614819"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 146ms/step - loss: 3.1384 - accuracy: 0.7500\n",
            "Model 3 Hidden Layer RMSprop Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 20.9274 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('RMSprop', 3, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaegkS_FoNgk",
        "outputId": "845c1ccc-6ea6-4161-a6fd-f279e5de651a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.70           0.76\n",
            "1        SGD             2                 0.70           0.60\n",
            "2        SGD             3                 0.75           0.68\n",
            "3        SGD             4                 0.70           0.52\n",
            "4       ADAM             1                 0.70           0.68\n",
            "5       ADAM             2                 0.65           0.60\n",
            "6       ADAM             3                 0.75           0.60\n",
            "7       ADAM             4                 0.60           0.60\n",
            "8    AdaGrad             1                 0.70           0.68\n",
            "9    AdaGrad             2                 0.65           0.60\n",
            "10   AdaGrad             3                 0.75           0.60\n",
            "11   AdaGrad             4                 0.60           0.60\n",
            "12   RMSprop             1                 0.70           0.64\n",
            "13   RMSprop             2                 0.65           0.60\n",
            "14   RMSprop             3                 0.75           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate the model with 4 hidden Layer with RMSProp Optimizer"
      ],
      "metadata": {
        "id": "T-n1jVk_H9Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "optimizer_rmsprop = tf.keras.optimizers.RMSprop()\n",
        "model_four_hidden_layer.compile(optimizer=optimizer_rmsprop, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_four_hidden_layer.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj00XOGcH_z9",
        "outputId": "f7f06408-12ae-4fc0-cba8-cca2823bc7fd"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 28ms/step - loss: 8.4153e-06 - accuracy: 1.0000 - val_loss: 3.4626 - val_accuracy: 0.6000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 6.9758e-06 - accuracy: 1.0000 - val_loss: 3.4760 - val_accuracy: 0.6000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 5.7581e-06 - accuracy: 1.0000 - val_loss: 3.4940 - val_accuracy: 0.6000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 5.0535e-06 - accuracy: 1.0000 - val_loss: 3.5094 - val_accuracy: 0.6000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.4424e-06 - accuracy: 1.0000 - val_loss: 3.5221 - val_accuracy: 0.6500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0033e-06 - accuracy: 1.0000 - val_loss: 3.5366 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.6260e-06 - accuracy: 1.0000 - val_loss: 3.5484 - val_accuracy: 0.6500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.3439e-06 - accuracy: 1.0000 - val_loss: 3.5601 - val_accuracy: 0.6500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.0722e-06 - accuracy: 1.0000 - val_loss: 3.5712 - val_accuracy: 0.6500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.8595e-06 - accuracy: 1.0000 - val_loss: 3.5823 - val_accuracy: 0.6500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.6678e-06 - accuracy: 1.0000 - val_loss: 3.5928 - val_accuracy: 0.6500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.4913e-06 - accuracy: 1.0000 - val_loss: 3.6012 - val_accuracy: 0.6500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 2.3555e-06 - accuracy: 1.0000 - val_loss: 3.6095 - val_accuracy: 0.6500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.2212e-06 - accuracy: 1.0000 - val_loss: 3.6174 - val_accuracy: 0.6500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.1095e-06 - accuracy: 1.0000 - val_loss: 3.6253 - val_accuracy: 0.6500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.0084e-06 - accuracy: 1.0000 - val_loss: 3.6329 - val_accuracy: 0.6500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.9088e-06 - accuracy: 1.0000 - val_loss: 3.6403 - val_accuracy: 0.6500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.8198e-06 - accuracy: 1.0000 - val_loss: 3.6474 - val_accuracy: 0.6500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.7444e-06 - accuracy: 1.0000 - val_loss: 3.6544 - val_accuracy: 0.6500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.6719e-06 - accuracy: 1.0000 - val_loss: 3.6608 - val_accuracy: 0.6500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.6071e-06 - accuracy: 1.0000 - val_loss: 3.6676 - val_accuracy: 0.6500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.5422e-06 - accuracy: 1.0000 - val_loss: 3.6743 - val_accuracy: 0.6500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.4818e-06 - accuracy: 1.0000 - val_loss: 3.6799 - val_accuracy: 0.6500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.4335e-06 - accuracy: 1.0000 - val_loss: 3.6854 - val_accuracy: 0.6500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.3807e-06 - accuracy: 1.0000 - val_loss: 3.6911 - val_accuracy: 0.6500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.3369e-06 - accuracy: 1.0000 - val_loss: 3.6964 - val_accuracy: 0.6500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2992e-06 - accuracy: 1.0000 - val_loss: 3.7018 - val_accuracy: 0.6500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2540e-06 - accuracy: 1.0000 - val_loss: 3.7068 - val_accuracy: 0.6500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2132e-06 - accuracy: 1.0000 - val_loss: 3.7116 - val_accuracy: 0.6500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1800e-06 - accuracy: 1.0000 - val_loss: 3.7162 - val_accuracy: 0.6500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1468e-06 - accuracy: 1.0000 - val_loss: 3.7209 - val_accuracy: 0.6500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1106e-06 - accuracy: 1.0000 - val_loss: 3.7254 - val_accuracy: 0.6500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0789e-06 - accuracy: 1.0000 - val_loss: 3.7298 - val_accuracy: 0.6500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0518e-06 - accuracy: 1.0000 - val_loss: 3.7342 - val_accuracy: 0.6500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0201e-06 - accuracy: 1.0000 - val_loss: 3.7385 - val_accuracy: 0.6500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 9.9592e-07 - accuracy: 1.0000 - val_loss: 3.7425 - val_accuracy: 0.6500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 9.7480e-07 - accuracy: 1.0000 - val_loss: 3.7466 - val_accuracy: 0.6500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 9.4764e-07 - accuracy: 1.0000 - val_loss: 3.7506 - val_accuracy: 0.6500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 9.2953e-07 - accuracy: 1.0000 - val_loss: 3.7549 - val_accuracy: 0.6500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 9.0689e-07 - accuracy: 1.0000 - val_loss: 3.7585 - val_accuracy: 0.6500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.8426e-07 - accuracy: 1.0000 - val_loss: 3.7625 - val_accuracy: 0.6500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.6162e-07 - accuracy: 1.0000 - val_loss: 3.7659 - val_accuracy: 0.6500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.4653e-07 - accuracy: 1.0000 - val_loss: 3.7695 - val_accuracy: 0.6500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 8.2692e-07 - accuracy: 1.0000 - val_loss: 3.7730 - val_accuracy: 0.6500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.1032e-07 - accuracy: 1.0000 - val_loss: 3.7764 - val_accuracy: 0.6500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.9674e-07 - accuracy: 1.0000 - val_loss: 3.7797 - val_accuracy: 0.6500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.7863e-07 - accuracy: 1.0000 - val_loss: 3.7828 - val_accuracy: 0.6500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 7.6203e-07 - accuracy: 1.0000 - val_loss: 3.7860 - val_accuracy: 0.6500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.4694e-07 - accuracy: 1.0000 - val_loss: 3.7891 - val_accuracy: 0.6500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.3487e-07 - accuracy: 1.0000 - val_loss: 3.7924 - val_accuracy: 0.6500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.2129e-07 - accuracy: 1.0000 - val_loss: 3.7955 - val_accuracy: 0.6500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 7.0771e-07 - accuracy: 1.0000 - val_loss: 3.7984 - val_accuracy: 0.6500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 6.9413e-07 - accuracy: 1.0000 - val_loss: 3.8013 - val_accuracy: 0.6500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.8206e-07 - accuracy: 1.0000 - val_loss: 3.8042 - val_accuracy: 0.6500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.6998e-07 - accuracy: 1.0000 - val_loss: 3.8071 - val_accuracy: 0.6500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 6.5791e-07 - accuracy: 1.0000 - val_loss: 3.8098 - val_accuracy: 0.6500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 6.4886e-07 - accuracy: 1.0000 - val_loss: 3.8126 - val_accuracy: 0.6500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.4433e-07 - accuracy: 1.0000 - val_loss: 3.8152 - val_accuracy: 0.6500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.2924e-07 - accuracy: 1.0000 - val_loss: 3.8179 - val_accuracy: 0.6500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 6.1415e-07 - accuracy: 1.0000 - val_loss: 3.8206 - val_accuracy: 0.6500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 6.0812e-07 - accuracy: 1.0000 - val_loss: 3.8231 - val_accuracy: 0.6500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 5.9605e-07 - accuracy: 1.0000 - val_loss: 3.8256 - val_accuracy: 0.6500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.9001e-07 - accuracy: 1.0000 - val_loss: 3.8283 - val_accuracy: 0.6500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.8246e-07 - accuracy: 1.0000 - val_loss: 3.8306 - val_accuracy: 0.6500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 5.7190e-07 - accuracy: 1.0000 - val_loss: 3.8330 - val_accuracy: 0.6500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 5.6587e-07 - accuracy: 1.0000 - val_loss: 3.8354 - val_accuracy: 0.6500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 5.5983e-07 - accuracy: 1.0000 - val_loss: 3.8378 - val_accuracy: 0.6500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 5.4625e-07 - accuracy: 1.0000 - val_loss: 3.8404 - val_accuracy: 0.6500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.3720e-07 - accuracy: 1.0000 - val_loss: 3.8427 - val_accuracy: 0.6500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 5.2965e-07 - accuracy: 1.0000 - val_loss: 3.8451 - val_accuracy: 0.6500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 5.2060e-07 - accuracy: 1.0000 - val_loss: 3.8474 - val_accuracy: 0.6500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 5.1305e-07 - accuracy: 1.0000 - val_loss: 3.8497 - val_accuracy: 0.6500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 5.0702e-07 - accuracy: 1.0000 - val_loss: 3.8519 - val_accuracy: 0.6500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.0098e-07 - accuracy: 1.0000 - val_loss: 3.8542 - val_accuracy: 0.6500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.9494e-07 - accuracy: 1.0000 - val_loss: 3.8564 - val_accuracy: 0.6500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.9193e-07 - accuracy: 1.0000 - val_loss: 3.8586 - val_accuracy: 0.6500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.8438e-07 - accuracy: 1.0000 - val_loss: 3.8609 - val_accuracy: 0.6500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.7985e-07 - accuracy: 1.0000 - val_loss: 3.8631 - val_accuracy: 0.6500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.7533e-07 - accuracy: 1.0000 - val_loss: 3.8652 - val_accuracy: 0.6500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.6778e-07 - accuracy: 1.0000 - val_loss: 3.8673 - val_accuracy: 0.6500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.6326e-07 - accuracy: 1.0000 - val_loss: 3.8694 - val_accuracy: 0.6500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.5571e-07 - accuracy: 1.0000 - val_loss: 3.8714 - val_accuracy: 0.6500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.4967e-07 - accuracy: 1.0000 - val_loss: 3.8734 - val_accuracy: 0.6500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 4.4364e-07 - accuracy: 1.0000 - val_loss: 3.8754 - val_accuracy: 0.6500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.3911e-07 - accuracy: 1.0000 - val_loss: 3.8773 - val_accuracy: 0.6500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.3760e-07 - accuracy: 1.0000 - val_loss: 3.8794 - val_accuracy: 0.6500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.3157e-07 - accuracy: 1.0000 - val_loss: 3.8814 - val_accuracy: 0.6500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.2704e-07 - accuracy: 1.0000 - val_loss: 3.8833 - val_accuracy: 0.6500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 4.2251e-07 - accuracy: 1.0000 - val_loss: 3.8852 - val_accuracy: 0.6500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1799e-07 - accuracy: 1.0000 - val_loss: 3.8871 - val_accuracy: 0.6500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1195e-07 - accuracy: 1.0000 - val_loss: 3.8889 - val_accuracy: 0.6500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 4.0591e-07 - accuracy: 1.0000 - val_loss: 3.8908 - val_accuracy: 0.6500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0139e-07 - accuracy: 1.0000 - val_loss: 3.8926 - val_accuracy: 0.6500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.9988e-07 - accuracy: 1.0000 - val_loss: 3.8944 - val_accuracy: 0.6500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9233e-07 - accuracy: 1.0000 - val_loss: 3.8962 - val_accuracy: 0.6500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.9082e-07 - accuracy: 1.0000 - val_loss: 3.8980 - val_accuracy: 0.6500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.8479e-07 - accuracy: 1.0000 - val_loss: 3.8997 - val_accuracy: 0.6500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 3.8177e-07 - accuracy: 1.0000 - val_loss: 3.9015 - val_accuracy: 0.6500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 3.7423e-07 - accuracy: 1.0000 - val_loss: 3.9031 - val_accuracy: 0.6500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.7272e-07 - accuracy: 1.0000 - val_loss: 3.9048 - val_accuracy: 0.6500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_four_hidden_layer.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 4 Hidden Layer RMSprop Optimizer Validation Accuracy:\", val_acc)\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_four_hidden_layer  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV7OR3ryICEV",
        "outputId": "71427bee-c50b-4a3b-9682-47933b0b2a3f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 156ms/step - loss: 3.9048 - accuracy: 0.6500\n",
            "Model 4 Hidden Layer RMSprop Optimizer Validation Accuracy: 0.6499999761581421\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 13.2340 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('RMSprop', 4, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBZP0voIoSYw",
        "outputId": "8fc62784-2e76-4f23-cd93-080f7e9298dc"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.70           0.76\n",
            "1        SGD             2                 0.70           0.60\n",
            "2        SGD             3                 0.75           0.68\n",
            "3        SGD             4                 0.70           0.52\n",
            "4       ADAM             1                 0.70           0.68\n",
            "5       ADAM             2                 0.65           0.60\n",
            "6       ADAM             3                 0.75           0.60\n",
            "7       ADAM             4                 0.60           0.60\n",
            "8    AdaGrad             1                 0.70           0.68\n",
            "9    AdaGrad             2                 0.65           0.60\n",
            "10   AdaGrad             3                 0.75           0.60\n",
            "11   AdaGrad             4                 0.60           0.60\n",
            "12   RMSprop             1                 0.70           0.64\n",
            "13   RMSprop             2                 0.65           0.60\n",
            "14   RMSprop             3                 0.75           0.60\n",
            "15   RMSprop             4                 0.65           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasil Optimizer"
      ],
      "metadata": {
        "id": "GmeHnc1YsBgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Membuat palet warna yang berbeda untuk setiap optimizer\n",
        "colors = {'SGD': 'blue', 'Adam': 'green', 'AdaGrad': 'orange', 'RMSprop': 'red'}\n",
        "\n",
        "# Membuat subplots\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
        "\n",
        "# Grafik akurasi validasi\n",
        "for optimizer, group in results_df.groupby('Optimizer'):\n",
        "    axs[0].bar(group['Optimizer'] + ' ' + group['Hidden Layers'].astype(str), group['Validation Accuracy'], color=colors.get(optimizer, 'black'), label=optimizer)\n",
        "axs[0].set_title('Validation Accuracy')\n",
        "axs[0].set_xlabel('Model', fontsize=10)  # Penyesuaian ukuran font\n",
        "axs[0].set_ylabel('Accuracy')\n",
        "axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=45, ha='right')  # Rotasi label sumbu x\n",
        "axs[0].legend()\n",
        "\n",
        "# Grafik akurasi pengujian\n",
        "for optimizer, group in results_df.groupby('Optimizer'):\n",
        "    axs[1].bar(group['Optimizer'] + ' ' + group['Hidden Layers'].astype(str), group['Test Accuracy'], color=colors.get(optimizer, 'black'), label=optimizer)\n",
        "axs[1].set_title('Test Accuracy')\n",
        "axs[1].set_xlabel('Model', fontsize=10)  # Penyesuaian ukuran font\n",
        "axs[1].set_ylabel('Accuracy')\n",
        "axs[1].set_xticklabels(axs[1].get_xticklabels(), rotation=45, ha='right')  # Rotasi label sumbu x\n",
        "axs[1].legend()\n",
        "\n",
        "# Menampilkan grafik\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "mTse-0aFojOj",
        "outputId": "9247c505-99a4-4db2-dd14-a49621c04efe"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "# Menampilkan DataFrame\n",
        "display(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "2flTOQ8MscmV",
        "outputId": "311911fe-6a01-4139-a1c2-06b3219e02dc"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
              "0        SGD             1                 0.70           0.76\n",
              "1        SGD             2                 0.70           0.60\n",
              "2        SGD             3                 0.75           0.68\n",
              "3        SGD             4                 0.70           0.52\n",
              "4       ADAM             1                 0.70           0.68\n",
              "5       ADAM             2                 0.65           0.60\n",
              "6       ADAM             3                 0.75           0.60\n",
              "7       ADAM             4                 0.60           0.60\n",
              "8    AdaGrad             1                 0.70           0.68\n",
              "9    AdaGrad             2                 0.65           0.60\n",
              "10   AdaGrad             3                 0.75           0.60\n",
              "11   AdaGrad             4                 0.60           0.60\n",
              "12   RMSprop             1                 0.70           0.64\n",
              "13   RMSprop             2                 0.65           0.60\n",
              "14   RMSprop             3                 0.75           0.60\n",
              "15   RMSprop             4                 0.65           0.60"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e91e71b9-c0d3-4b77-b493-7e326771930f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>Hidden Layers</th>\n",
              "      <th>Validation Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SGD</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SGD</td>\n",
              "      <td>2</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SGD</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SGD</td>\n",
              "      <td>4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>2</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>4</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>2</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>4</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>2</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>4</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e91e71b9-c0d3-4b77-b493-7e326771930f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e91e71b9-c0d3-4b77-b493-7e326771930f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e91e71b9-c0d3-4b77-b493-7e326771930f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cd2af6de-f39c-45b1-b417-bb8968737cef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd2af6de-f39c-45b1-b417-bb8968737cef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cd2af6de-f39c-45b1-b417-bb8968737cef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"Optimizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"ADAM\",\n          \"RMSprop\",\n          \"SGD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hidden Layers\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04999999801318072,\n        \"min\": 0.6000000238418579,\n        \"max\": 0.75,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.75,\n          0.6000000238418579,\n          0.699999988079071\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.054589371691799185,\n        \"min\": 0.5199999809265137,\n        \"max\": 0.7599999904632568,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6000000238418579,\n          0.6399999856948853,\n          0.6800000071525574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Temukan indeks baris dengan akurasi pengujian tertinggi dan terendah\n",
        "best_model_idx = results_df['Test Accuracy'].idxmax()\n",
        "worst_model_idx = results_df['Test Accuracy'].idxmin()\n",
        "\n",
        "# Dapatkan informasi tentang model dengan akurasi pengujian tertinggi dan terendah\n",
        "best_model_info = results_df.loc[best_model_idx]\n",
        "worst_model_info = results_df.loc[worst_model_idx]\n",
        "\n",
        "print(\"Model dengan akurasi pengujian tertinggi:\")\n",
        "print(best_model_info)\n",
        "print(\"\\nModel dengan akurasi pengujian terendah:\")\n",
        "print(worst_model_info)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgdEHufkrdwC",
        "outputId": "b581235e-b3f2-4a43-f8df-7f59dd6db4b3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model dengan akurasi pengujian tertinggi:\n",
            "Optimizer               SGD\n",
            "Hidden Layers             1\n",
            "Validation Accuracy     0.7\n",
            "Test Accuracy          0.76\n",
            "Name: 0, dtype: object\n",
            "\n",
            "Model dengan akurasi pengujian terendah:\n",
            "Optimizer               SGD\n",
            "Hidden Layers             4\n",
            "Validation Accuracy     0.7\n",
            "Test Accuracy          0.52\n",
            "Name: 3, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menambahkan Dropout 50%"
      ],
      "metadata": {
        "id": "ux_JFcoEv1Jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build the DNN model with one hidden layer\n",
        "def build_model_one_hidden_with_dropout():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(1000, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Hidden layer with 1000 neurons and ReLU activation\n",
        "        tf.keras.layers.Dropout(0.5),  # Dropout layer with dropout rate of 50%\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')          # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Function to build the DNN model with two hidden layer\n",
        "def build_model_two_hidden_with_dropout():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(500, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # 1st hidden layer with 500 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(500, activation='relu'),                                   # 2nd hidden layer with 500 neurons and ReLU activation\n",
        "        tf.keras.layers.Dropout(0.5),  # Dropout layer with dropout rate of 50%\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')         # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Function to build the DNN model with three hidden layer\n",
        "def build_model_three_hidden_with_dropout():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(250, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # First hidden layer with 250 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(250, activation='relu'),                                   # Second hidden layer with 250 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(250, activation='relu'),                                   # Third hidden layer with 250 neurons and ReLU activation\n",
        "        tf.keras.layers.Dropout(0.5),  # Dropout layer with dropout rate of 50%\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')         # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Function to build the DNN model with four hidden layer\n",
        "def build_model_four_hidden_with_dropout():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # First hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(100, activation='relu'),                                   # Second hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(100, activation='relu'),                                   # Third hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dense(100, activation='relu'),                                   # Fourth hidden layer with 100 neurons and ReLU activation\n",
        "        tf.keras.layers.Dropout(0.5),  # Dropout layer with dropout rate of 50%\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='sigmoid')         # Output layer with sigmoid activation\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "yQLoXTcixR9v"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the DNN model\n",
        "model_one_hidden_layer_with_dropout = build_model_one_hidden_with_dropout()\n",
        "model_two_hidden_layer_with_dropout = build_model_two_hidden_with_dropout()\n",
        "model_three_hidden_layer_with_dropout = build_model_three_hidden_with_dropout()\n",
        "model_four_hidden_layer_with_dropout = build_model_four_hidden_with_dropout()"
      ],
      "metadata": {
        "id": "Ovt6qsAIys18"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD - Train and evaluate the model with 1 hidden Layer"
      ],
      "metadata": {
        "id": "XFZMsLntyDkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "# optimizer_sgd = tf.keras.optimizers.SGD(learning_rate=0.01)  # Define the optimizer with learning rate\n",
        "model_one_hidden_layer_with_dropout.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_one_hidden_layer_with_dropout.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upboAKNMyWRR",
        "outputId": "8b961e6a-6667-4bb2-a202-0447ccfd61bc"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 54ms/step - loss: 1.6524 - accuracy: 0.5823 - val_loss: 2.5821 - val_accuracy: 0.6000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.9119 - accuracy: 0.7975 - val_loss: 2.0558 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1065 - accuracy: 0.9620 - val_loss: 1.5822 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0325 - accuracy: 0.9873 - val_loss: 1.6046 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0301 - accuracy: 0.9873 - val_loss: 1.4639 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.5010 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5264 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.5870 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.6042 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6092 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6195 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0294 - accuracy: 0.9873 - val_loss: 1.8580 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.7764 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7631 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 7.8679e-04 - accuracy: 1.0000 - val_loss: 1.7635 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 8.5750e-04 - accuracy: 1.0000 - val_loss: 1.7560 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0226 - accuracy: 0.9873 - val_loss: 1.7716 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7348 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7431 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7727 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 8.2508e-04 - accuracy: 1.0000 - val_loss: 1.7670 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 8.7792e-04 - accuracy: 1.0000 - val_loss: 1.7622 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 7.7024e-04 - accuracy: 1.0000 - val_loss: 1.7590 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 5.5234e-04 - accuracy: 1.0000 - val_loss: 1.7541 - val_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7847 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.2273e-04 - accuracy: 1.0000 - val_loss: 1.7853 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 4.6866e-04 - accuracy: 1.0000 - val_loss: 1.7880 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7790 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 6.3555e-04 - accuracy: 1.0000 - val_loss: 1.7738 - val_accuracy: 0.7500\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 64ms/step - loss: 2.3388e-04 - accuracy: 1.0000 - val_loss: 1.7755 - val_accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.9948e-04 - accuracy: 1.0000 - val_loss: 1.7759 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 5.5394e-04 - accuracy: 1.0000 - val_loss: 1.7735 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7771 - val_accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 8.4725e-04 - accuracy: 1.0000 - val_loss: 1.7739 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.9146e-04 - accuracy: 1.0000 - val_loss: 1.7749 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 9.6753e-04 - accuracy: 1.0000 - val_loss: 1.7801 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 4.9319e-04 - accuracy: 1.0000 - val_loss: 1.7788 - val_accuracy: 0.7500\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.3497e-04 - accuracy: 1.0000 - val_loss: 1.7800 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7852 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 2.1129e-04 - accuracy: 1.0000 - val_loss: 1.7863 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 4.7614e-04 - accuracy: 1.0000 - val_loss: 1.7764 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.7039e-04 - accuracy: 1.0000 - val_loss: 1.7754 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.1868e-04 - accuracy: 1.0000 - val_loss: 1.7766 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 4.3184e-04 - accuracy: 1.0000 - val_loss: 1.7804 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7812 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.5173e-04 - accuracy: 1.0000 - val_loss: 1.7847 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.5944e-04 - accuracy: 1.0000 - val_loss: 1.7852 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.7989e-04 - accuracy: 1.0000 - val_loss: 1.7862 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 7.0002e-04 - accuracy: 1.0000 - val_loss: 1.7747 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 2.2843e-04 - accuracy: 1.0000 - val_loss: 1.7752 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.5342e-04 - accuracy: 1.0000 - val_loss: 1.7772 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0313e-04 - accuracy: 1.0000 - val_loss: 1.7762 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.7082 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 7.3821e-04 - accuracy: 1.0000 - val_loss: 1.7092 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 6.9334e-04 - accuracy: 1.0000 - val_loss: 1.7120 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.3947e-04 - accuracy: 1.0000 - val_loss: 1.7133 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.0865e-04 - accuracy: 1.0000 - val_loss: 1.7140 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.6562e-04 - accuracy: 1.0000 - val_loss: 1.7161 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.3025e-04 - accuracy: 1.0000 - val_loss: 1.7167 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 5.6278e-04 - accuracy: 1.0000 - val_loss: 1.7160 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 4.9316e-04 - accuracy: 1.0000 - val_loss: 1.7183 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 3.6167e-04 - accuracy: 1.0000 - val_loss: 1.7161 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.7383e-04 - accuracy: 1.0000 - val_loss: 1.7161 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7182 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 4.2963e-04 - accuracy: 1.0000 - val_loss: 1.7234 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 5.4418e-04 - accuracy: 1.0000 - val_loss: 1.7323 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 5.7774e-04 - accuracy: 1.0000 - val_loss: 1.7410 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 4.0045e-04 - accuracy: 1.0000 - val_loss: 1.7376 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 7.7528e-04 - accuracy: 1.0000 - val_loss: 1.7556 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.6749e-04 - accuracy: 1.0000 - val_loss: 1.7554 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 6.7653e-04 - accuracy: 1.0000 - val_loss: 1.7539 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.4261e-04 - accuracy: 1.0000 - val_loss: 1.7535 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.4116e-04 - accuracy: 1.0000 - val_loss: 1.7535 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.6942e-04 - accuracy: 1.0000 - val_loss: 1.7535 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.7581e-04 - accuracy: 1.0000 - val_loss: 1.7554 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 5.0670e-04 - accuracy: 1.0000 - val_loss: 1.7517 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.9125e-04 - accuracy: 1.0000 - val_loss: 1.7510 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.4116e-04 - accuracy: 1.0000 - val_loss: 1.7517 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.4182e-04 - accuracy: 1.0000 - val_loss: 1.7529 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.7728e-04 - accuracy: 1.0000 - val_loss: 1.7520 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 3.1374e-04 - accuracy: 1.0000 - val_loss: 1.7502 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.6036e-04 - accuracy: 1.0000 - val_loss: 1.7502 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 2.8094e-04 - accuracy: 1.0000 - val_loss: 1.7527 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.9068e-04 - accuracy: 1.0000 - val_loss: 1.7539 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 4.1183e-04 - accuracy: 1.0000 - val_loss: 1.7578 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 2.8022e-04 - accuracy: 1.0000 - val_loss: 1.7588 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 9.0521e-05 - accuracy: 1.0000 - val_loss: 1.7588 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7073 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.0859e-04 - accuracy: 1.0000 - val_loss: 1.7091 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 6.4833e-04 - accuracy: 1.0000 - val_loss: 1.7130 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 8.8745e-05 - accuracy: 1.0000 - val_loss: 1.7138 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 7.9598e-04 - accuracy: 1.0000 - val_loss: 1.7088 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.3200e-04 - accuracy: 1.0000 - val_loss: 1.7090 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.9068e-04 - accuracy: 1.0000 - val_loss: 1.7100 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 2.8048e-04 - accuracy: 1.0000 - val_loss: 1.7115 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 2.1437e-04 - accuracy: 1.0000 - val_loss: 1.7114 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.5344e-04 - accuracy: 1.0000 - val_loss: 1.7110 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 2.1517e-04 - accuracy: 1.0000 - val_loss: 1.7123 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7236 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 4.8734e-04 - accuracy: 1.0000 - val_loss: 1.7272 - val_accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_one_hidden_layer_with_dropout.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_one_hidden_layer_with_dropout  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JNF5onKzMtW",
        "outputId": "c6a30f2e-f24c-4514-b1e8-efdca2c4f51f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 107ms/step - loss: 1.7272 - accuracy: 0.7500\n",
            "Model Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 3.8164 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('SGD+D', 1, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X17iNYBXzR-_",
        "outputId": "97ad3e92-6e68-4e44-c99f-717a833d219f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.70           0.76\n",
            "1        SGD             2                 0.70           0.60\n",
            "2        SGD             3                 0.75           0.68\n",
            "3        SGD             4                 0.70           0.52\n",
            "4       ADAM             1                 0.70           0.68\n",
            "5       ADAM             2                 0.65           0.60\n",
            "6       ADAM             3                 0.75           0.60\n",
            "7       ADAM             4                 0.60           0.60\n",
            "8    AdaGrad             1                 0.70           0.68\n",
            "9    AdaGrad             2                 0.65           0.60\n",
            "10   AdaGrad             3                 0.75           0.60\n",
            "11   AdaGrad             4                 0.60           0.60\n",
            "12   RMSprop             1                 0.70           0.64\n",
            "13   RMSprop             2                 0.65           0.60\n",
            "14   RMSprop             3                 0.75           0.60\n",
            "15   RMSprop             4                 0.65           0.60\n",
            "16     SGD+D             1                 0.75           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD - Train and evaluate the model with 2 hidden Layer"
      ],
      "metadata": {
        "id": "Zh84YYGJyJje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_two_hidden_layer_with_dropout.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_two_hidden_layer_with_dropout.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpJsI-9gycRD",
        "outputId": "ad76cf20-5b80-4444-ca02-464cef92979e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 37ms/step - loss: 1.1840 - accuracy: 0.5823 - val_loss: 0.9667 - val_accuracy: 0.5500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.2849 - accuracy: 0.8861 - val_loss: 0.6517 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0794 - accuracy: 0.9747 - val_loss: 0.6925 - val_accuracy: 0.8000\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.8000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0382 - accuracy: 0.9873 - val_loss: 0.8095 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.8364 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.8466 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8560 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.8198 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.8329 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8383 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.8574 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8644 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8653 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.8754 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8736 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8831 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8885 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8905 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8934 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9031 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.8962 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8894 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8932 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8926 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9024 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9011 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9048 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9072 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9133 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9130 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9154 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9179 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9211 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9211 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9304 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9226 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9248 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9301 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9324 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9303 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9317 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9335 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9400 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9459 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9475 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9494 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 9.6567e-04 - accuracy: 1.0000 - val_loss: 0.9533 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9547 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9614 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9607 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9565 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9.9670e-04 - accuracy: 1.0000 - val_loss: 0.9604 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9617 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9649 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 8.8170e-04 - accuracy: 1.0000 - val_loss: 0.9670 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 8.3879e-04 - accuracy: 1.0000 - val_loss: 0.9688 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 8.3596e-04 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 7.9000e-04 - accuracy: 1.0000 - val_loss: 0.9709 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 9.1096e-04 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9694 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 8.8878e-04 - accuracy: 1.0000 - val_loss: 0.9697 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 7.5327e-04 - accuracy: 1.0000 - val_loss: 0.9720 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9728 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9775 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 8.9674e-04 - accuracy: 1.0000 - val_loss: 0.9751 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9787 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9806 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.7241e-04 - accuracy: 1.0000 - val_loss: 0.9830 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 6.9363e-04 - accuracy: 1.0000 - val_loss: 0.9860 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 4.9623e-04 - accuracy: 1.0000 - val_loss: 0.9880 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9858 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 5.8145e-04 - accuracy: 1.0000 - val_loss: 0.9861 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9895 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9899 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 9.1296e-04 - accuracy: 1.0000 - val_loss: 0.9902 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9909 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9927 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 6.4305e-04 - accuracy: 1.0000 - val_loss: 0.9943 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 9.4657e-04 - accuracy: 1.0000 - val_loss: 0.9958 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 4.1224e-04 - accuracy: 1.0000 - val_loss: 0.9961 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 9.2440e-04 - accuracy: 1.0000 - val_loss: 0.9975 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 7.0731e-04 - accuracy: 1.0000 - val_loss: 0.9965 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 9.6817e-04 - accuracy: 1.0000 - val_loss: 0.9990 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 6.8368e-04 - accuracy: 1.0000 - val_loss: 1.0000 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 4.3122e-04 - accuracy: 1.0000 - val_loss: 0.9995 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0044 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0331 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 6.3121e-04 - accuracy: 1.0000 - val_loss: 1.0347 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 7.6333e-04 - accuracy: 1.0000 - val_loss: 1.0353 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 5.4103e-04 - accuracy: 1.0000 - val_loss: 1.0361 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0213 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0285 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_two_hidden_layer_with_dropout.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 2 Hidden Layer SGD Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# 5. Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_two_hidden_layer_with_dropout  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# 6. Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88kGQAjMzyqi",
        "outputId": "7ab1ccb7-244a-4ad8-a178-59c5150fb83e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 103ms/step - loss: 1.0285 - accuracy: 0.7000\n",
            "Model 2 Hidden Layer SGD Optimizer Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.9643 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('SGD+D', 2, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyI3oLO0z6vY",
        "outputId": "ef8a3eb8-645c-485f-8169-730dbf392996"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.70           0.76\n",
            "1        SGD             2                 0.70           0.60\n",
            "2        SGD             3                 0.75           0.68\n",
            "3        SGD             4                 0.70           0.52\n",
            "4       ADAM             1                 0.70           0.68\n",
            "5       ADAM             2                 0.65           0.60\n",
            "6       ADAM             3                 0.75           0.60\n",
            "7       ADAM             4                 0.60           0.60\n",
            "8    AdaGrad             1                 0.70           0.68\n",
            "9    AdaGrad             2                 0.65           0.60\n",
            "10   AdaGrad             3                 0.75           0.60\n",
            "11   AdaGrad             4                 0.60           0.60\n",
            "12   RMSprop             1                 0.70           0.64\n",
            "13   RMSprop             2                 0.65           0.60\n",
            "14   RMSprop             3                 0.75           0.60\n",
            "15   RMSprop             4                 0.65           0.60\n",
            "16     SGD+D             1                 0.75           0.60\n",
            "17     SGD+D             2                 0.70           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD - Train and evaluate the model with 3 hidden Layer"
      ],
      "metadata": {
        "id": "nwjT0dniyKty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_three_hidden_layer_with_dropout.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_three_hidden_layer_with_dropout.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf3FhJMDyYJn",
        "outputId": "c899fad5-0c8d-4147-b7f3-b51fa2557c19"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 31ms/step - loss: 0.8785 - accuracy: 0.4557 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.3458 - accuracy: 0.8608 - val_loss: 0.5367 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1552 - accuracy: 0.9620 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1194 - accuracy: 0.9747 - val_loss: 0.5333 - val_accuracy: 0.6500\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.5329 - val_accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.5426 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.5586 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.5679 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5778 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.5825 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.5857 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5896 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.6070 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.6172 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.6267 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6302 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6329 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6330 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6369 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6534 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6662 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6736 - val_accuracy: 0.7000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6779 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6812 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6827 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6882 - val_accuracy: 0.7000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.7000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.7000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.7000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.7000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.7000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.7000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7135 - val_accuracy: 0.7000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.7000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7213 - val_accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7254 - val_accuracy: 0.7000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7279 - val_accuracy: 0.7000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7297 - val_accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7283 - val_accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7308 - val_accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7335 - val_accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7360 - val_accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7368 - val_accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7355 - val_accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.7000\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7411 - val_accuracy: 0.7000\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7453 - val_accuracy: 0.7000\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7445 - val_accuracy: 0.7000\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7470 - val_accuracy: 0.7000\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7470 - val_accuracy: 0.7000\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7491 - val_accuracy: 0.7000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7529 - val_accuracy: 0.7000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7596 - val_accuracy: 0.7000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7622 - val_accuracy: 0.7000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7625 - val_accuracy: 0.7000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7655 - val_accuracy: 0.7000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7716 - val_accuracy: 0.7000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7737 - val_accuracy: 0.7000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7762 - val_accuracy: 0.7000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7783 - val_accuracy: 0.7000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7843 - val_accuracy: 0.7000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.4186e-04 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.7000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7871 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7917 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7949 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 8.1075e-04 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8062 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8081 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8076 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8081 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8107 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8129 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_three_hidden_layer_with_dropout.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer SGD Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_three_hidden_layer_with_dropout  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPXAb-SB0Keo",
        "outputId": "6d88fed7-d559-41a5-fd57-aad64c9efa03"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 116ms/step - loss: 0.8129 - accuracy: 0.7000\n",
            "Model 3 Hidden Layer SGD Optimizer Validation Accuracy: 0.699999988079071\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.1450 - accuracy: 0.6000\n",
            "Best Model Test Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('SGD+D', 3, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq5Ybvoz0T88",
        "outputId": "d0a3a620-1c07-4eb0-e657-08cc04de6096"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.70           0.76\n",
            "1        SGD             2                 0.70           0.60\n",
            "2        SGD             3                 0.75           0.68\n",
            "3        SGD             4                 0.70           0.52\n",
            "4       ADAM             1                 0.70           0.68\n",
            "5       ADAM             2                 0.65           0.60\n",
            "6       ADAM             3                 0.75           0.60\n",
            "7       ADAM             4                 0.60           0.60\n",
            "8    AdaGrad             1                 0.70           0.68\n",
            "9    AdaGrad             2                 0.65           0.60\n",
            "10   AdaGrad             3                 0.75           0.60\n",
            "11   AdaGrad             4                 0.60           0.60\n",
            "12   RMSprop             1                 0.70           0.64\n",
            "13   RMSprop             2                 0.65           0.60\n",
            "14   RMSprop             3                 0.75           0.60\n",
            "15   RMSprop             4                 0.65           0.60\n",
            "16     SGD+D             1                 0.75           0.60\n",
            "17     SGD+D             2                 0.70           0.60\n",
            "18     SGD+D             3                 0.70           0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD - Train and evaluate the model with 4 hidden Layer"
      ],
      "metadata": {
        "id": "R5XOintSyL4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "model_four_hidden_layer_with_dropout.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_four_hidden_layer_with_dropout.fit(X_train_scaled, y_train, epochs=100, batch_size=10, validation_data=(X_val_scaled, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz4Zfyf-yjHn",
        "outputId": "8ab38654-419b-4b99-8bea-bb4f6f7c8186"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 26ms/step - loss: 0.7035 - accuracy: 0.5570 - val_loss: 0.6026 - val_accuracy: 0.7500\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5024 - accuracy: 0.7468 - val_loss: 0.5907 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3665 - accuracy: 0.8861 - val_loss: 0.5427 - val_accuracy: 0.6500\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2664 - accuracy: 0.9873 - val_loss: 0.5453 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2611 - accuracy: 0.9114 - val_loss: 0.5531 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1695 - accuracy: 0.9494 - val_loss: 0.5643 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1486 - accuracy: 0.9494 - val_loss: 0.5928 - val_accuracy: 0.6500\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1042 - accuracy: 0.9873 - val_loss: 0.5947 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0904 - accuracy: 0.9873 - val_loss: 0.6020 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.6039 - val_accuracy: 0.7000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.6433 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.6783 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0495 - accuracy: 0.9873 - val_loss: 0.7099 - val_accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.7213 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.7242 - val_accuracy: 0.7000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.7000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.7371 - val_accuracy: 0.7000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.7601 - val_accuracy: 0.7000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.7831 - val_accuracy: 0.7000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.7849 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.7953 - val_accuracy: 0.7000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.8097 - val_accuracy: 0.7000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.7000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.8228 - val_accuracy: 0.7000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.8238 - val_accuracy: 0.7000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.8386 - val_accuracy: 0.7000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.8597 - val_accuracy: 0.7000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.8678 - val_accuracy: 0.7000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.8704 - val_accuracy: 0.7000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.8740 - val_accuracy: 0.7000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.8762 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.8816 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.8870 - val_accuracy: 0.7000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.8937 - val_accuracy: 0.7000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9090 - val_accuracy: 0.7000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.9159 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.9223 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.9267 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9324 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9340 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.9374 - val_accuracy: 0.7500\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.9436 - val_accuracy: 0.7500\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9472 - val_accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9561 - val_accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.9439 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9436 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.9530 - val_accuracy: 0.7500\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9592 - val_accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.9781 - val_accuracy: 0.7500\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9849 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9835 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.0012 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9963 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.0025 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0091 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0157 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0178 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0232 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0264 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0338 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0364 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0383 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0419 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0521 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0557 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0590 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0611 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0724 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0751 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0829 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0799 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0869 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0922 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0996 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1121 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1146 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1221 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.1277 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1297 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.9276e-04 - accuracy: 1.0000 - val_loss: 1.1318 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1479 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1497 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1533 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1548 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1554 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1794 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1821 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1849 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2223e-04 - accuracy: 1.0000 - val_loss: 1.1862 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1848 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.8784e-04 - accuracy: 1.0000 - val_loss: 1.1878 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1915 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1932 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1906 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1944 - val_accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi kinerja model menggunakan data validasi\n",
        "val_loss, val_acc = model_four_hidden_layer_with_dropout.evaluate(X_val_scaled, y_val)\n",
        "print(\"Model 3 Hidden Layer SGD Optimizer Validation Accuracy:\", val_acc)\n",
        "\n",
        "# Pilih model terbaik berdasarkan kinerja validasi\n",
        "best_model = model_four_hidden_layer_with_dropout  # Misalnya, model pertama dianggap sebagai model terbaik\n",
        "\n",
        "# Evaluasi akhir menggunakan data pengujian\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best Model Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6lcrKw00jbQ",
        "outputId": "015c4b23-8de6-4b2d-bfbe-28dabb2f337a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 109ms/step - loss: 1.1944 - accuracy: 0.7500\n",
            "Model 3 Hidden Layer SGD Optimizer Validation Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 4.1212 - accuracy: 0.4000\n",
            "Best Model Test Accuracy: 0.4000000059604645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_results('SGD+D', 4, val_acc, test_acc)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kqYtKpt0tYT",
        "outputId": "f6bdd4ad-c77b-459e-e7ae-4f463ee71163"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
            "0        SGD             1                 0.70           0.76\n",
            "1        SGD             2                 0.70           0.60\n",
            "2        SGD             3                 0.75           0.68\n",
            "3        SGD             4                 0.70           0.52\n",
            "4       ADAM             1                 0.70           0.68\n",
            "5       ADAM             2                 0.65           0.60\n",
            "6       ADAM             3                 0.75           0.60\n",
            "7       ADAM             4                 0.60           0.60\n",
            "8    AdaGrad             1                 0.70           0.68\n",
            "9    AdaGrad             2                 0.65           0.60\n",
            "10   AdaGrad             3                 0.75           0.60\n",
            "11   AdaGrad             4                 0.60           0.60\n",
            "12   RMSprop             1                 0.70           0.64\n",
            "13   RMSprop             2                 0.65           0.60\n",
            "14   RMSprop             3                 0.75           0.60\n",
            "15   RMSprop             4                 0.65           0.60\n",
            "16     SGD+D             1                 0.75           0.60\n",
            "17     SGD+D             2                 0.70           0.60\n",
            "18     SGD+D             3                 0.70           0.60\n",
            "19     SGD+D             4                 0.75           0.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasil Penambahan Dropout 50%"
      ],
      "metadata": {
        "id": "hCE5O4uR028V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "# Menampilkan DataFrame\n",
        "display(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "MImc1AD-1Lp_",
        "outputId": "ff386bb1-b312-4873-a0f0-e63f446b5c49"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Optimizer Hidden Layers  Validation Accuracy  Test Accuracy\n",
              "0        SGD             1                 0.70           0.76\n",
              "1        SGD             2                 0.70           0.60\n",
              "2        SGD             3                 0.75           0.68\n",
              "3        SGD             4                 0.70           0.52\n",
              "4       ADAM             1                 0.70           0.68\n",
              "5       ADAM             2                 0.65           0.60\n",
              "6       ADAM             3                 0.75           0.60\n",
              "7       ADAM             4                 0.60           0.60\n",
              "8    AdaGrad             1                 0.70           0.68\n",
              "9    AdaGrad             2                 0.65           0.60\n",
              "10   AdaGrad             3                 0.75           0.60\n",
              "11   AdaGrad             4                 0.60           0.60\n",
              "12   RMSprop             1                 0.70           0.64\n",
              "13   RMSprop             2                 0.65           0.60\n",
              "14   RMSprop             3                 0.75           0.60\n",
              "15   RMSprop             4                 0.65           0.60\n",
              "16     SGD+D             1                 0.75           0.60\n",
              "17     SGD+D             2                 0.70           0.60\n",
              "18     SGD+D             3                 0.70           0.60\n",
              "19     SGD+D             4                 0.75           0.40"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30fe2697-2f0e-497a-bbe6-3edde488fde5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>Hidden Layers</th>\n",
              "      <th>Validation Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SGD</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SGD</td>\n",
              "      <td>2</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SGD</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SGD</td>\n",
              "      <td>4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>2</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ADAM</td>\n",
              "      <td>4</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>2</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>AdaGrad</td>\n",
              "      <td>4</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>2</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>4</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>SGD+D</td>\n",
              "      <td>1</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>SGD+D</td>\n",
              "      <td>2</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>SGD+D</td>\n",
              "      <td>3</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>SGD+D</td>\n",
              "      <td>4</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30fe2697-2f0e-497a-bbe6-3edde488fde5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30fe2697-2f0e-497a-bbe6-3edde488fde5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30fe2697-2f0e-497a-bbe6-3edde488fde5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-92d39175-42c0-4f34-af7e-2165a7397ff1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92d39175-42c0-4f34-af7e-2165a7397ff1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-92d39175-42c0-4f34-af7e-2165a7397ff1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Optimizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ADAM\",\n          \"SGD+D\",\n          \"AdaGrad\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hidden Layers\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0483953012994857,\n        \"min\": 0.6000000238418579,\n        \"max\": 0.75,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.75,\n          0.6000000238418579,\n          0.699999988079071\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06940347147145237,\n        \"min\": 0.4000000059604645,\n        \"max\": 0.7599999904632568,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.7599999904632568,\n          0.6000000238418579,\n          0.4000000059604645\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Temukan indeks baris dengan akurasi pengujian tertinggi dan terendah\n",
        "best_model_idx = results_df['Test Accuracy'].idxmax()\n",
        "worst_model_idx = results_df['Test Accuracy'].idxmin()\n",
        "\n",
        "# Dapatkan informasi tentang model dengan akurasi pengujian tertinggi dan terendah\n",
        "best_model_info = results_df.loc[best_model_idx]\n",
        "worst_model_info = results_df.loc[worst_model_idx]\n",
        "\n",
        "print(\"Model dengan akurasi pengujian tertinggi:\")\n",
        "print(best_model_info)\n",
        "print(\"\\nModel dengan akurasi pengujian terendah:\")\n",
        "print(worst_model_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zguDGXib1REK",
        "outputId": "d2e20d46-44b1-416f-bf4e-74e6b2ae5534"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model dengan akurasi pengujian tertinggi:\n",
            "Optimizer               SGD\n",
            "Hidden Layers             1\n",
            "Validation Accuracy     0.7\n",
            "Test Accuracy          0.76\n",
            "Name: 0, dtype: object\n",
            "\n",
            "Model dengan akurasi pengujian terendah:\n",
            "Optimizer              SGD+D\n",
            "Hidden Layers              4\n",
            "Validation Accuracy     0.75\n",
            "Test Accuracy            0.4\n",
            "Name: 19, dtype: object\n"
          ]
        }
      ]
    }
  ]
}